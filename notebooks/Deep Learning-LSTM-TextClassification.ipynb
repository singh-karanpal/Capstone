{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model - LSTM Multi-Label Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D, GlobalMaxPooling1D, MaxPool1D, MaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import spacy\n",
    "# from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Q1 = pd.read_excel('../data/interim/X_train_Q1_clean.xlsx')\n",
    "X_valid_Q1 = pd.read_excel('../data/interim/X_valid_Q1_clean.xlsx')\n",
    "\n",
    "y_train_Q1 = pd.read_excel('../data/interim/y_train_Q1.xlsx')\n",
    "y_valid_Q1 = pd.read_excel('../data/interim/y_valid_Q1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Unified Dataframe for LSTM Ready Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X_train_Q1, y_train_Q1.iloc[:,0:12]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>CPD</th>\n",
       "      <th>CB</th>\n",
       "      <th>EWC</th>\n",
       "      <th>Exec</th>\n",
       "      <th>FEW</th>\n",
       "      <th>SP</th>\n",
       "      <th>RE</th>\n",
       "      <th>Sup</th>\n",
       "      <th>SW</th>\n",
       "      <th>TEPE</th>\n",
       "      <th>VMG</th>\n",
       "      <th>OTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to be real about diversity, you need to create...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keep the building warmer and provide warm wate...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>better communication from the top down</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It would be beneficial if Management did not m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>more education applicable to my job</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  CPD  CB  EWC  Exec  FEW  \\\n",
       "0  to be real about diversity, you need to create...    0   0    1     0    0   \n",
       "1  Keep the building warmer and provide warm wate...    0   0    0     0    0   \n",
       "2             better communication from the top down    0   0    0     1    0   \n",
       "3  It would be beneficial if Management did not m...    0   0    0     0    0   \n",
       "4                more education applicable to my job    1   0    0     0    0   \n",
       "\n",
       "   SP  RE  Sup  SW  TEPE  VMG  OTH  \n",
       "0   0   0    0   0     0    0    0  \n",
       "1   0   0    0   0     1    0    0  \n",
       "2   0   0    0   0     0    0    0  \n",
       "3   0   1    0   0     0    0    0  \n",
       "4   0   0    0   0     0    0    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10376, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves',\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "preprocessed_synopsis = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in data_df['Comment'].values:\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    preprocessed_synopsis.append(sentance.strip())\n",
    "data_df['preprocessed_comments']=preprocessed_synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>CPD</th>\n",
       "      <th>CB</th>\n",
       "      <th>EWC</th>\n",
       "      <th>Exec</th>\n",
       "      <th>FEW</th>\n",
       "      <th>SP</th>\n",
       "      <th>RE</th>\n",
       "      <th>Sup</th>\n",
       "      <th>SW</th>\n",
       "      <th>TEPE</th>\n",
       "      <th>VMG</th>\n",
       "      <th>OTH</th>\n",
       "      <th>preprocessed_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to be real about diversity, you need to create...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>real diversity you need create seats table mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keep the building warmer and provide warm wate...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>keep building warmer provide warm water bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>better communication from the top down</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>better communication top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It would be beneficial if Management did not m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>would beneficial management not micro manage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>more education applicable to my job</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>education applicable job</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  CPD  CB  EWC  Exec  FEW  \\\n",
       "0  to be real about diversity, you need to create...    0   0    1     0    0   \n",
       "1  Keep the building warmer and provide warm wate...    0   0    0     0    0   \n",
       "2             better communication from the top down    0   0    0     1    0   \n",
       "3  It would be beneficial if Management did not m...    0   0    0     0    0   \n",
       "4                more education applicable to my job    1   0    0     0    0   \n",
       "\n",
       "   SP  RE  Sup  SW  TEPE  VMG  OTH  \\\n",
       "0   0   0    0   0     0    0    0   \n",
       "1   0   0    0   0     1    0    0   \n",
       "2   0   0    0   0     0    0    0   \n",
       "3   0   1    0   0     0    0    0   \n",
       "4   0   0    0   0     0    0    0   \n",
       "\n",
       "                               preprocessed_comments  \n",
       "0  real diversity you need create seats table mea...  \n",
       "1   keep building warmer provide warm water bathroom  \n",
       "2                           better communication top  \n",
       "3       would beneficial management not micro manage  \n",
       "4                           education applicable job  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_df[['preprocessed_comments']]\n",
    "y_train = data_df.drop(['Comment', 'preprocessed_comments'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(\",\"), binary='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = vectorizer.fit_transform(y_train['tags']).toarray()\n",
    "# y_test=vectorizer.transform(y_test['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_len(x):\n",
    "    a=x.split()\n",
    "    return len(a)\n",
    "\n",
    "max_len = max(data_df['Comment'].apply(max_len))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11919\n"
     ]
    }
   ],
   "source": [
    "vect=Tokenizer()\n",
    "vect.fit_on_texts(X_train['preprocessed_comments'])\n",
    "vocab_size = len(vect.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding to make all sequences of same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  504   585    36 ...     0     0     0]\n",
      " [  134    54  3393 ...     0     0     0]\n",
      " [    7    29   234 ...     0     0     0]\n",
      " ...\n",
      " [  697     4    12 ...     0     0     0]\n",
      " [  476  2745 11917 ...     0     0     0]\n",
      " [ 1147   593   791 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "encoded_docs_train = vect.texts_to_sequences(X_train['preprocessed_comments'])\n",
    "max_length = vocab_size\n",
    "padded_docs_train = pad_sequences(encoded_docs_train, maxlen=max_len, padding='post')\n",
    "print(padded_docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10376, 150)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3aa6e173b86e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoded_docs_test\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessed_comments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpadded_docs_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_docs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#encoded_docs_cv = vect.texts_to_sequences(cv['preprocessed_plots'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#padded_docs_cv = pad_sequences(encoded_docs_cv, maxlen=1200, padding='post')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_docs_test =  vect.texts_to_sequences(X_test['preprocessed_comments'])\n",
    "padded_docs_test = pad_sequences(encoded_docs_test, maxlen=max_len, padding='post')\n",
    "\n",
    "#encoded_docs_cv = vect.texts_to_sequences(cv['preprocessed_plots'])\n",
    "#padded_docs_cv = pad_sequences(encoded_docs_cv, maxlen=1200, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_docs_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(Embedding(vocab_size, output_dim=50, input_length=1200))\n",
    "model.add(LSTM(128, return_sequences=True))  \n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.fit(padded_docs_train, y_train,\n",
    "                    class_weight='balanced',\n",
    "                    epochs=5,\n",
    "                    batch_size=12,\n",
    "                    verbose=1,\n",
    "                    validation_data=(padded_docs_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_docs_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"metal_amd_radeon_pro_555x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 50)           595950    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150, 120)          82080     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 150, 120)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                47360     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 726,170\n",
      "Trainable params: 726,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Configuring the parameters\n",
    "model.add(Embedding(vocab_size, output_dim=50, input_length=max_len))\n",
    "model.add(LSTM(120, return_sequences=True))  \n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.1))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(12, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_orignal = np.array(df.iloc[:,1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karan/anaconda3/lib/python3.7/site-packages/numpy/ctypeslib.py:436: RuntimeWarning: Invalid PEP 3118 format string: '&<q'\n",
      "  return array(obj, copy=False)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8819 samples, validate on 1557 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 3405 of 30423 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 7785 of 30423 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 12789 of 30423 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 19814 of 30423 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 25453 of 30423 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 29728 of 30423 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4032/8819 [============>.................] - ETA: 4:50 - loss: 1.7545 - acc: 0.0839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karan/anaconda3/lib/python3.7/site-packages/numpy/ctypeslib.py:436: RuntimeWarning: Invalid PEP 3118 format string: '&<f'\n",
      "  return array(obj, copy=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8800/8819 [============================>.] - ETA: 1s - loss: 1.8200 - acc: 0.0384"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 3045 of 30424 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 7510 of 30424 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 12298 of 30424 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 19224 of 30424 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 24973 of 30424 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 29114 of 30424 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 3901 of 12541 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 10744 of 12541 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 6532 of 12542 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8819/8819 [==============================] - 636s 72ms/step - loss: 1.8200 - acc: 0.0383 - val_loss: nan - val_acc: -1.8471e-16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2faa4890>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs_train, y_train_orignal, epochs=1, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('/Users/karan/Downloads/glove/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in vect.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.11619   ,  0.45447001, -0.69216001, ..., -0.54737002,\n",
       "         0.48822001,  0.32246   ],\n",
       "       [-0.19103999,  0.17601   ,  0.36919999, ..., -0.59680003,\n",
       "         0.080843  ,  0.27866   ],\n",
       "       ...,\n",
       "       [-0.34926   ,  0.27006999, -0.52661002, ...,  0.22747   ,\n",
       "        -0.12559   ,  0.70643002],\n",
       "       [-0.53812999,  0.72706997,  0.074018  , ..., -0.41005999,\n",
       "         1.08850002,  0.75314999],\n",
       "       [-1.51540005,  0.66566002,  0.23134001, ...,  0.47402   ,\n",
       "         0.84129   ,  0.94787002]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 150, 100)          1191900   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 150, 120)          106080    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 150, 120)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                47360     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 1,346,120\n",
      "Trainable params: 154,220\n",
      "Non-trainable params: 1,191,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Configuring the parameters\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_len, weights=[embedding_matrix], trainable=False))\n",
    "\n",
    "model.add(LSTM(120, return_sequences=True))  \n",
    "\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "\n",
    "model.add(Dense(12, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karan/anaconda3/lib/python3.7/site-packages/numpy/ctypeslib.py:436: RuntimeWarning: Invalid PEP 3118 format string: '&<q'\n",
      "  return array(obj, copy=False)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karan/anaconda3/lib/python3.7/site-packages/numpy/ctypeslib.py:436: RuntimeWarning: Invalid PEP 3118 format string: '&<f'\n",
      "  return array(obj, copy=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8819 samples, validate on 1557 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1765 of 29060 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 6553 of 29060 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 10474 of 29060 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 17388 of 29060 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 24271 of 29060 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8704/8819 [============================>.] - ETA: 12s - loss: 1.5369 - acc: 0.2165"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 3034 of 29060 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 7472 of 29060 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 12171 of 29060 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 19409 of 29060 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 25173 of 29060 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 5036 of 12542 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 11856 of 12542 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 4061 of 12542 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 11066 of 12542 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8819/8819 [==============================] - 1152s 131ms/step - loss: 1.5420 - acc: 0.2137 - val_loss: 1.8832 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a37aaef50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(padded_docs_train, y_train, batch_size=128, epochs=1, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with Universal Sentence Encorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03669859, -0.07417478,  0.03231422, ...,  0.01621998,\n",
       "         0.00728293,  0.00265464],\n",
       "       [ 0.05218186, -0.01258108, -0.04657765, ...,  0.05539099,\n",
       "         0.05895472, -0.0171202 ],\n",
       "       [-0.01777638, -0.04568463,  0.00473103, ..., -0.00073464,\n",
       "        -0.08261821,  0.05859691],\n",
       "       ...,\n",
       "       [ 0.03823395,  0.01441879,  0.06019125, ...,  0.06164353,\n",
       "        -0.02452262, -0.01176131],\n",
       "       [-0.03514517, -0.04318713, -0.02938136, ...,  0.0648592 ,\n",
       "        -0.05883494,  0.01129983],\n",
       "       [ 0.02614759, -0.05074428,  0.00971   , ...,  0.01864268,\n",
       "         0.05439513,  0.03895477]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "embeddings = embed(X_train['preprocessed_comments'])\n",
    "embedding_matrix = np.array(embeddings)\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10376, 512)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_df[['Comment']]\n",
    "y_train = data_df.drop(columns='Comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving embeddings as pickle file\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embeddings = embed(X_train['Comment'])\n",
    "embedding_matrix = np.array(embeddings)\n",
    "\n",
    "#embedding_matrix.save('../models/use_x_train_embeddings.pkl')\n",
    "np.save('../models/use_x_train_embeddings', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving y_train as pickle\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../models/y_train', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving X_valid data\n",
    "\n",
    "df_valid = pd.concat([X_valid_Q1, y_valid_Q1.iloc[:,:12]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = df_valid[['Comment']]\n",
    "y_valid = df_valid.drop(columns='Comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_valid = embed(X_valid['Comment'])\n",
    "embedding_matrix_valid = np.array(embeddings_valid)\n",
    "np.save('../models/use_x_valid_embeddings', embedding_matrix_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving y_valid\n",
    "y_valid = np.array(y_valid)\n",
    "np.save('../models/y_valid', y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = embedding_matrix.shape[0]\n",
    "maxlen = max_len\n",
    "batch_size = 128\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 1\n",
    "embed_size = 512 # for universal sentence encoder\n",
    "n_class = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karan/anaconda3/lib/python3.7/site-packages/numpy/ctypeslib.py:436: RuntimeWarning: Invalid PEP 3118 format string: '&<I'\n",
      "  return array(obj, copy=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 512, 512)          5312512   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 512, 120)          303840    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512, 120)          0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                47360     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 5,664,492\n",
      "Trainable params: 5,664,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Configuring the parameters\n",
    "model.add(Embedding(max_features, embed_size, input_length=embed_size))\n",
    "\n",
    "model.add(LSTM(120, return_sequences=True))  \n",
    "\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "\n",
    "model.add(Dense(12, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karan/anaconda3/lib/python3.7/site-packages/numpy/ctypeslib.py:436: RuntimeWarning: Invalid PEP 3118 format string: '&<q'\n",
      "  return array(obj, copy=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8819 samples, validate on 1557 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1475 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 1475 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 2621 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 2621 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 3827 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 3827 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 5081 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 5081 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 6409 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 6409 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 7882 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 7882 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 9506 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 9506 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 11226 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 11226 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 12843 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 12843 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 15199 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 15199 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 18277 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 18277 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 21878 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 21878 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 23504 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 23504 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 24623 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 24623 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 25799 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 25799 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 27026 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 27026 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 28292 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 28292 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 29688 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 29688 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 31197 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 31197 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 32956 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 32956 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 34980 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 34980 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 37450 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 37450 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 40794 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 40794 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 46835 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 46835 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 53482 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 53482 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 60023 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 60023 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 66309 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 66309 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 72508 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 72508 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 78678 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 78678 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 83888 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 83888 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 87489 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 87489 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 93075 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 93075 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 96677 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 96677 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 100278 of 103185 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 100278 of 103185 operations complete\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "model.fit(embedding_matrix, y_train, batch_size=batch_size, epochs=epochs,\n",
    "          validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
