{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recall-50-above-Glove-100d-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPIGC2tTV0IM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c1d13cd-9cf3-4ab7-ed83-0679e6aaa635"
      },
      "source": [
        "import os\n",
        "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras import models\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv1D, Conv2D, MaxPooling2D, GlobalMaxPooling1D, MaxPool1D, MaxPooling1D, GlobalMaxPool1D, SpatialDropout1D, GlobalAveragePooling1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import spacy\n",
        "# from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prd4WmnnWlUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing data and embeddings\n",
        "X_train = np.load('glove_x_train_padded.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "\n",
        "X_valid = np.load('glove_x_valid_padded.npy')\n",
        "y_valid = np.load('y_valid.npy')\n",
        "\n",
        "glove_embeddings = np.load('glove_embedding_100d.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9syeCyCuWo5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = glove_embeddings.shape[0]\n",
        "maxlen = 150\n",
        "batch_size = 128\n",
        "filters = 250\n",
        "kernel_size = 3\n",
        "hidden_dims = 250\n",
        "epochs = 50\n",
        "embed_size = 100 # for glove we are using 100d dataset\n",
        "n_class = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sec72VIkYUIj",
        "colab_type": "text"
      },
      "source": [
        "#### Using L2 Regularization - This is not having a DROPOUT in your Model. This is different!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6maCz_tWvcf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "98cd94a3-1c8f-4baf-ccad-3e38825bd4e7"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, embed_size, weights=[glove_embeddings], trainable=False, input_length=maxlen))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(filters, kernel_size, padding='valid', activation='relu',\n",
        "                 strides=1))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(filters, kernel_size, padding='valid',activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Flatten())\n",
        "\n",
        "# L2 regularization\n",
        "model.add(Dense(hidden_dims, activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "model.add(Dense(hidden_dims, activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "model.add(Dense(n_class, activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 150, 100)          1191900   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 150, 100)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 148, 250)          75250     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 74, 250)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 72, 250)           187750    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 36, 250)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9000)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 250)               2250250   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 250)               62750     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 12)                3012      \n",
            "=================================================================\n",
            "Total params: 3,770,912\n",
            "Trainable params: 2,579,012\n",
            "Non-trainable params: 1,191,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DunBgbDAW72P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e73507ec-19af-492f-9874-a1bd21b44ac2"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=50,class_weight='auto'  ,validation_split=0.15)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8819 samples, validate on 1557 samples\n",
            "Epoch 1/50\n",
            "8819/8819 [==============================] - 8s 939us/step - loss: 0.6095 - accuracy: 0.8801 - val_loss: 0.4123 - val_accuracy: 0.8945\n",
            "Epoch 2/50\n",
            "8819/8819 [==============================] - 1s 110us/step - loss: 0.3639 - accuracy: 0.8976 - val_loss: 0.3203 - val_accuracy: 0.9019\n",
            "Epoch 3/50\n",
            "8819/8819 [==============================] - 1s 108us/step - loss: 0.3061 - accuracy: 0.9034 - val_loss: 0.2808 - val_accuracy: 0.9107\n",
            "Epoch 4/50\n",
            "8819/8819 [==============================] - 1s 106us/step - loss: 0.2722 - accuracy: 0.9117 - val_loss: 0.2611 - val_accuracy: 0.9184\n",
            "Epoch 5/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.2504 - accuracy: 0.9189 - val_loss: 0.2488 - val_accuracy: 0.9208\n",
            "Epoch 6/50\n",
            "8819/8819 [==============================] - 1s 107us/step - loss: 0.2368 - accuracy: 0.9221 - val_loss: 0.2414 - val_accuracy: 0.9228\n",
            "Epoch 7/50\n",
            "8819/8819 [==============================] - 1s 105us/step - loss: 0.2237 - accuracy: 0.9263 - val_loss: 0.2354 - val_accuracy: 0.9249\n",
            "Epoch 8/50\n",
            "8819/8819 [==============================] - 1s 106us/step - loss: 0.2159 - accuracy: 0.9291 - val_loss: 0.2335 - val_accuracy: 0.9253\n",
            "Epoch 9/50\n",
            "8819/8819 [==============================] - 1s 105us/step - loss: 0.2085 - accuracy: 0.9312 - val_loss: 0.2301 - val_accuracy: 0.9257\n",
            "Epoch 10/50\n",
            "8819/8819 [==============================] - 1s 106us/step - loss: 0.2000 - accuracy: 0.9342 - val_loss: 0.2266 - val_accuracy: 0.9273\n",
            "Epoch 11/50\n",
            "8819/8819 [==============================] - 1s 111us/step - loss: 0.1943 - accuracy: 0.9370 - val_loss: 0.2261 - val_accuracy: 0.9272\n",
            "Epoch 12/50\n",
            "8819/8819 [==============================] - 1s 110us/step - loss: 0.1861 - accuracy: 0.9399 - val_loss: 0.2242 - val_accuracy: 0.9274\n",
            "Epoch 13/50\n",
            "8819/8819 [==============================] - 1s 110us/step - loss: 0.1815 - accuracy: 0.9416 - val_loss: 0.2251 - val_accuracy: 0.9277\n",
            "Epoch 14/50\n",
            "8819/8819 [==============================] - 1s 106us/step - loss: 0.1767 - accuracy: 0.9436 - val_loss: 0.2276 - val_accuracy: 0.9268\n",
            "Epoch 15/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.1719 - accuracy: 0.9462 - val_loss: 0.2266 - val_accuracy: 0.9292\n",
            "Epoch 16/50\n",
            "8819/8819 [==============================] - 1s 108us/step - loss: 0.1637 - accuracy: 0.9496 - val_loss: 0.2219 - val_accuracy: 0.9306\n",
            "Epoch 17/50\n",
            "8819/8819 [==============================] - 1s 106us/step - loss: 0.1596 - accuracy: 0.9505 - val_loss: 0.2292 - val_accuracy: 0.9293\n",
            "Epoch 18/50\n",
            "8819/8819 [==============================] - 1s 106us/step - loss: 0.1531 - accuracy: 0.9543 - val_loss: 0.2344 - val_accuracy: 0.9283\n",
            "Epoch 19/50\n",
            "8819/8819 [==============================] - 1s 108us/step - loss: 0.1473 - accuracy: 0.9566 - val_loss: 0.2412 - val_accuracy: 0.9245\n",
            "Epoch 20/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.1445 - accuracy: 0.9580 - val_loss: 0.2398 - val_accuracy: 0.9264\n",
            "Epoch 21/50\n",
            "8819/8819 [==============================] - 1s 107us/step - loss: 0.1382 - accuracy: 0.9607 - val_loss: 0.2447 - val_accuracy: 0.9265\n",
            "Epoch 22/50\n",
            "8819/8819 [==============================] - 1s 106us/step - loss: 0.1331 - accuracy: 0.9630 - val_loss: 0.2441 - val_accuracy: 0.9278\n",
            "Epoch 23/50\n",
            "8819/8819 [==============================] - 1s 106us/step - loss: 0.1284 - accuracy: 0.9647 - val_loss: 0.2515 - val_accuracy: 0.9267\n",
            "Epoch 24/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.1228 - accuracy: 0.9673 - val_loss: 0.2512 - val_accuracy: 0.9261\n",
            "Epoch 25/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.1189 - accuracy: 0.9687 - val_loss: 0.2620 - val_accuracy: 0.9229\n",
            "Epoch 26/50\n",
            "8819/8819 [==============================] - 1s 107us/step - loss: 0.1160 - accuracy: 0.9707 - val_loss: 0.2706 - val_accuracy: 0.9241\n",
            "Epoch 27/50\n",
            "8819/8819 [==============================] - 1s 106us/step - loss: 0.1103 - accuracy: 0.9723 - val_loss: 0.2701 - val_accuracy: 0.9241\n",
            "Epoch 28/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.1065 - accuracy: 0.9744 - val_loss: 0.2750 - val_accuracy: 0.9243\n",
            "Epoch 29/50\n",
            "8819/8819 [==============================] - 1s 110us/step - loss: 0.1043 - accuracy: 0.9753 - val_loss: 0.2813 - val_accuracy: 0.9235\n",
            "Epoch 30/50\n",
            "8819/8819 [==============================] - 1s 107us/step - loss: 0.1003 - accuracy: 0.9766 - val_loss: 0.2833 - val_accuracy: 0.9266\n",
            "Epoch 31/50\n",
            "8819/8819 [==============================] - 1s 107us/step - loss: 0.0962 - accuracy: 0.9779 - val_loss: 0.2935 - val_accuracy: 0.9184\n",
            "Epoch 32/50\n",
            "8819/8819 [==============================] - 1s 106us/step - loss: 0.0943 - accuracy: 0.9793 - val_loss: 0.2788 - val_accuracy: 0.9257\n",
            "Epoch 33/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.0894 - accuracy: 0.9809 - val_loss: 0.2930 - val_accuracy: 0.9240\n",
            "Epoch 34/50\n",
            "8819/8819 [==============================] - 1s 110us/step - loss: 0.0878 - accuracy: 0.9815 - val_loss: 0.2946 - val_accuracy: 0.9236\n",
            "Epoch 35/50\n",
            "8819/8819 [==============================] - 1s 108us/step - loss: 0.0851 - accuracy: 0.9823 - val_loss: 0.2971 - val_accuracy: 0.9229\n",
            "Epoch 36/50\n",
            "8819/8819 [==============================] - 1s 107us/step - loss: 0.0836 - accuracy: 0.9827 - val_loss: 0.2987 - val_accuracy: 0.9242\n",
            "Epoch 37/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.0805 - accuracy: 0.9839 - val_loss: 0.3118 - val_accuracy: 0.9245\n",
            "Epoch 38/50\n",
            "8819/8819 [==============================] - 1s 110us/step - loss: 0.0779 - accuracy: 0.9850 - val_loss: 0.3147 - val_accuracy: 0.9222\n",
            "Epoch 39/50\n",
            "8819/8819 [==============================] - 1s 108us/step - loss: 0.0767 - accuracy: 0.9852 - val_loss: 0.3137 - val_accuracy: 0.9230\n",
            "Epoch 40/50\n",
            "8819/8819 [==============================] - 1s 107us/step - loss: 0.0762 - accuracy: 0.9854 - val_loss: 0.3122 - val_accuracy: 0.9193\n",
            "Epoch 41/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.0728 - accuracy: 0.9869 - val_loss: 0.3300 - val_accuracy: 0.9215\n",
            "Epoch 42/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.0718 - accuracy: 0.9870 - val_loss: 0.3156 - val_accuracy: 0.9213\n",
            "Epoch 43/50\n",
            "8819/8819 [==============================] - 1s 108us/step - loss: 0.0676 - accuracy: 0.9885 - val_loss: 0.3239 - val_accuracy: 0.9222\n",
            "Epoch 44/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.0671 - accuracy: 0.9885 - val_loss: 0.3344 - val_accuracy: 0.9252\n",
            "Epoch 45/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.0660 - accuracy: 0.9889 - val_loss: 0.3217 - val_accuracy: 0.9214\n",
            "Epoch 46/50\n",
            "8819/8819 [==============================] - 1s 113us/step - loss: 0.0642 - accuracy: 0.9894 - val_loss: 0.3226 - val_accuracy: 0.9241\n",
            "Epoch 47/50\n",
            "8819/8819 [==============================] - 1s 109us/step - loss: 0.0622 - accuracy: 0.9900 - val_loss: 0.3405 - val_accuracy: 0.9241\n",
            "Epoch 48/50\n",
            "8819/8819 [==============================] - 1s 110us/step - loss: 0.0633 - accuracy: 0.9898 - val_loss: 0.3420 - val_accuracy: 0.9231\n",
            "Epoch 49/50\n",
            "8819/8819 [==============================] - 1s 107us/step - loss: 0.0592 - accuracy: 0.9906 - val_loss: 0.3378 - val_accuracy: 0.9215\n",
            "Epoch 50/50\n",
            "8819/8819 [==============================] - 1s 108us/step - loss: 0.0610 - accuracy: 0.9899 - val_loss: 0.3343 - val_accuracy: 0.9192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f57501e0898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D65wEnFtXhnj",
        "colab_type": "text"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZndU3y5XAuK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f4c2aa6-9ee7-46f9-801f-d12eeee8824a"
      },
      "source": [
        "score = model.evaluate(X_valid,y_valid)\n",
        "score"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2594/2594 [==============================] - 0s 102us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3199956518646011, 0.9249230027198792]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ejw71ocX5OC",
        "colab_type": "text"
      },
      "source": [
        "## Precision & Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl-CRAl2XtN7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "bf7b1cd3-8dcf-4627-9391-501d4014f4a3"
      },
      "source": [
        "pred = model.predict(X_valid, batch_size=batch_size, verbose=1)\n",
        "\n",
        "predictions = pred\n",
        "thresholds=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "\n",
        "for val in thresholds:\n",
        "    print(\"For threshold: \", val)\n",
        "    pred=predictions.copy()\n",
        "  \n",
        "    pred[pred>=val]=1\n",
        "    pred[pred<val]=0\n",
        "  \n",
        "    precision = precision_score(y_valid, pred, average='micro')\n",
        "    recall = recall_score(y_valid, pred, average='micro')\n",
        "    f1 = f1_score(y_valid, pred, average='micro')\n",
        "   \n",
        "    print(\"Micro-average quality numbers\")\n",
        "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
        "    print('\\n')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2594/2594 [==============================] - 0s 65us/step\n",
            "For threshold:  0.1\n",
            "Micro-average quality numbers\n",
            "Precision: 0.5223, Recall: 0.7532, F1-measure: 0.6169\n",
            "\n",
            "\n",
            "For threshold:  0.2\n",
            "Micro-average quality numbers\n",
            "Precision: 0.5921, Recall: 0.7153, F1-measure: 0.6479\n",
            "\n",
            "\n",
            "For threshold:  0.3\n",
            "Micro-average quality numbers\n",
            "Precision: 0.6293, Recall: 0.6866, F1-measure: 0.6567\n",
            "\n",
            "\n",
            "For threshold:  0.4\n",
            "Micro-average quality numbers\n",
            "Precision: 0.6593, Recall: 0.6578, F1-measure: 0.6586\n",
            "\n",
            "\n",
            "For threshold:  0.5\n",
            "Micro-average quality numbers\n",
            "Precision: 0.6910, Recall: 0.6404, F1-measure: 0.6648\n",
            "\n",
            "\n",
            "For threshold:  0.6\n",
            "Micro-average quality numbers\n",
            "Precision: 0.7194, Recall: 0.6213, F1-measure: 0.6668\n",
            "\n",
            "\n",
            "For threshold:  0.7\n",
            "Micro-average quality numbers\n",
            "Precision: 0.7483, Recall: 0.5948, F1-measure: 0.6628\n",
            "\n",
            "\n",
            "For threshold:  0.8\n",
            "Micro-average quality numbers\n",
            "Precision: 0.7736, Recall: 0.5658, F1-measure: 0.6536\n",
            "\n",
            "\n",
            "For threshold:  0.9\n",
            "Micro-average quality numbers\n",
            "Precision: 0.8111, Recall: 0.5174, F1-measure: 0.6318\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85zCYUQDX_73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}