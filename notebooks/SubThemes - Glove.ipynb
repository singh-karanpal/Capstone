{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-Themes (Glove 100d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Bidirectional, GRU\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D, GlobalMaxPooling1D, MaxPool1D, MaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import spacy\n",
    "# from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Q1 = pd.read_excel('../data/interim/X_train_Q1_clean.xlsx')\n",
    "X_valid_Q1 = pd.read_excel('../data/interim/X_valid_Q1_clean.xlsx')\n",
    "\n",
    "y_train_Q1 = pd.read_excel('../data/interim/y_train_Q1.xlsx')\n",
    "y_valid_Q1 = pd.read_excel('../data/interim/y_valid_Q1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>CPD_Improve_new_employee_orientation</th>\n",
       "      <th>CPD_Improve_performance</th>\n",
       "      <th>CPD_Improve_training</th>\n",
       "      <th>CPD_Provide_opportunities_advancement</th>\n",
       "      <th>CPD_other</th>\n",
       "      <th>CB_Ensure_salary_parity_across_gov</th>\n",
       "      <th>CB_Ensure_salary_parity_with_other_orgs</th>\n",
       "      <th>CB_Improve_medical</th>\n",
       "      <th>CB_Increase_salary</th>\n",
       "      <th>...</th>\n",
       "      <th>VMG_Improve_collaboration</th>\n",
       "      <th>VMG_Improve_program</th>\n",
       "      <th>VMG_Pay_attention_to_the_public_interest</th>\n",
       "      <th>VMG_Review_funding_or_budget</th>\n",
       "      <th>VMG_Remove_political_influence</th>\n",
       "      <th>VMG_other</th>\n",
       "      <th>OTH_Other_related</th>\n",
       "      <th>OTH_Positive_comments</th>\n",
       "      <th>OTH_Survey_feedback</th>\n",
       "      <th>OTH_Covid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to be real about diversity, you need to create...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keep the building warmer and provide warm wate...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>better communication from the top down</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It would be beneficial if Management did not m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>more education applicable to my job</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  to be real about diversity, you need to create...   \n",
       "1  Keep the building warmer and provide warm wate...   \n",
       "2             better communication from the top down   \n",
       "3  It would be beneficial if Management did not m...   \n",
       "4                more education applicable to my job   \n",
       "\n",
       "   CPD_Improve_new_employee_orientation  CPD_Improve_performance  \\\n",
       "0                                     0                        0   \n",
       "1                                     0                        0   \n",
       "2                                     0                        0   \n",
       "3                                     0                        0   \n",
       "4                                     0                        0   \n",
       "\n",
       "   CPD_Improve_training  CPD_Provide_opportunities_advancement  CPD_other  \\\n",
       "0                     0                                      0          0   \n",
       "1                     0                                      0          0   \n",
       "2                     0                                      0          0   \n",
       "3                     0                                      0          0   \n",
       "4                     1                                      0          0   \n",
       "\n",
       "   CB_Ensure_salary_parity_across_gov  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "\n",
       "   CB_Ensure_salary_parity_with_other_orgs  CB_Improve_medical  \\\n",
       "0                                        0                   0   \n",
       "1                                        0                   0   \n",
       "2                                        0                   0   \n",
       "3                                        0                   0   \n",
       "4                                        0                   0   \n",
       "\n",
       "   CB_Increase_salary  ...  VMG_Improve_collaboration  VMG_Improve_program  \\\n",
       "0                   0  ...                          0                    0   \n",
       "1                   0  ...                          0                    0   \n",
       "2                   0  ...                          0                    0   \n",
       "3                   0  ...                          0                    0   \n",
       "4                   0  ...                          0                    0   \n",
       "\n",
       "   VMG_Pay_attention_to_the_public_interest  VMG_Review_funding_or_budget  \\\n",
       "0                                         0                             0   \n",
       "1                                         0                             0   \n",
       "2                                         0                             0   \n",
       "3                                         0                             0   \n",
       "4                                         0                             0   \n",
       "\n",
       "   VMG_Remove_political_influence  VMG_other  OTH_Other_related  \\\n",
       "0                               0          0                  0   \n",
       "1                               0          0                  0   \n",
       "2                               0          0                  0   \n",
       "3                               0          0                  0   \n",
       "4                               0          0                  0   \n",
       "\n",
       "   OTH_Positive_comments  OTH_Survey_feedback  OTH_Covid  \n",
       "0                      0                    0          0  \n",
       "1                      0                    0          0  \n",
       "2                      0                    0          0  \n",
       "3                      0                    0          0  \n",
       "4                      0                    0          0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([X_train_Q1, y_train_Q1.iloc[:,12:-1]], axis = 1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>CPD_Improve_new_employee_orientation</th>\n",
       "      <th>CPD_Improve_performance</th>\n",
       "      <th>CPD_Improve_training</th>\n",
       "      <th>CPD_Provide_opportunities_advancement</th>\n",
       "      <th>CPD_other</th>\n",
       "      <th>CB_Ensure_salary_parity_across_gov</th>\n",
       "      <th>CB_Ensure_salary_parity_with_other_orgs</th>\n",
       "      <th>CB_Improve_medical</th>\n",
       "      <th>CB_Increase_salary</th>\n",
       "      <th>...</th>\n",
       "      <th>VMG_Improve_collaboration</th>\n",
       "      <th>VMG_Improve_program</th>\n",
       "      <th>VMG_Pay_attention_to_the_public_interest</th>\n",
       "      <th>VMG_Review_funding_or_budget</th>\n",
       "      <th>VMG_Remove_political_influence</th>\n",
       "      <th>VMG_other</th>\n",
       "      <th>OTH_Other_related</th>\n",
       "      <th>OTH_Positive_comments</th>\n",
       "      <th>OTH_Survey_feedback</th>\n",
       "      <th>OTH_Covid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Change management and articulating a clear vis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>More interaction with Management, not this us ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We switched to safetyline for field monitoring...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JCM's used to be treated as the Managers they ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actively providing the adequate training/knowl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  Change management and articulating a clear vis...   \n",
       "1  More interaction with Management, not this us ...   \n",
       "2  We switched to safetyline for field monitoring...   \n",
       "3  JCM's used to be treated as the Managers they ...   \n",
       "4  actively providing the adequate training/knowl...   \n",
       "\n",
       "   CPD_Improve_new_employee_orientation  CPD_Improve_performance  \\\n",
       "0                                     0                        0   \n",
       "1                                     0                        0   \n",
       "2                                     0                        0   \n",
       "3                                     0                        0   \n",
       "4                                     0                        0   \n",
       "\n",
       "   CPD_Improve_training  CPD_Provide_opportunities_advancement  CPD_other  \\\n",
       "0                     0                                      0          0   \n",
       "1                     0                                      0          0   \n",
       "2                     0                                      0          0   \n",
       "3                     0                                      0          0   \n",
       "4                     0                                      0          0   \n",
       "\n",
       "   CB_Ensure_salary_parity_across_gov  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "\n",
       "   CB_Ensure_salary_parity_with_other_orgs  CB_Improve_medical  \\\n",
       "0                                        0                   0   \n",
       "1                                        0                   0   \n",
       "2                                        0                   0   \n",
       "3                                        0                   0   \n",
       "4                                        0                   0   \n",
       "\n",
       "   CB_Increase_salary  ...  VMG_Improve_collaboration  VMG_Improve_program  \\\n",
       "0                   0  ...                          0                    0   \n",
       "1                   0  ...                          0                    0   \n",
       "2                   0  ...                          0                    0   \n",
       "3                   0  ...                          0                    0   \n",
       "4                   0  ...                          0                    0   \n",
       "\n",
       "   VMG_Pay_attention_to_the_public_interest  VMG_Review_funding_or_budget  \\\n",
       "0                                         0                             0   \n",
       "1                                         0                             0   \n",
       "2                                         0                             0   \n",
       "3                                         0                             0   \n",
       "4                                         0                             0   \n",
       "\n",
       "   VMG_Remove_political_influence  VMG_other  OTH_Other_related  \\\n",
       "0                               0          0                  0   \n",
       "1                               0          0                  0   \n",
       "2                               0          0                  0   \n",
       "3                               0          0                  0   \n",
       "4                               0          0                  0   \n",
       "\n",
       "   OTH_Positive_comments  OTH_Survey_feedback  OTH_Covid  \n",
       "0                      0                    0          0  \n",
       "1                      0                    0          0  \n",
       "2                      0                    0          0  \n",
       "3                      0                    0          0  \n",
       "4                      0                    0          0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.concat([X_valid_Q1, y_valid_Q1.iloc[:,12:-1]], axis = 1)\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_train = df_train\n",
    "data_df_valid = df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "# function adapted from `preprocess` function of lab 3 \n",
    "# of this course (575 Advance Learning Machine)\n",
    "def preprocess_comments(text, \n",
    "                        min_token_len = 2, \n",
    "                        irrelevant_pos = ['PRON', 'SPACE', 'PUNCT', 'ADV', \n",
    "                                          'ADP', 'CCONJ', 'AUX', 'PRP'],\n",
    "                        avoid_entities = ['PERSON', 'ORG', 'LOC', 'GPE']):\n",
    "# note: Didn't use the following options in the `preprocess_comments`...\n",
    "#    - 'PROPN' because it erases proper names as 'George', but also words as orange.\n",
    "#    - 'DET' since it removes the word 'no', which changes the meaning of a sentence.\n",
    "# *for more information see link: https://universaldependencies.org/u/pos/\n",
    "    \"\"\"\n",
    "    Given text, min_token_len, irrelevant_pos and avoid_entities, carries out \n",
    "    preprocessing of the text and returns list of preprocessed text. \n",
    "    Parameters\n",
    "    -------------\n",
    "    text : (list) \n",
    "        the list of text to be preprocessed\n",
    "    min_token_len : (int) \n",
    "        min_token_length required\n",
    "    irrelevant_pos : (list) \n",
    "        a list of irrelevant pos tags\n",
    "    avoid_entities : (list)\n",
    "        a list of entity labels to be avoided\n",
    "    Returns\n",
    "    -------------\n",
    "    (list) list of preprocessed text\n",
    "    Example\n",
    "    -------------\n",
    "    >>> example = [\"Hello, I'm George and I love swimming!\",\n",
    "                   \"I am a really good cook; what about you?\",\n",
    "                   \"Contact me at george23@gmail.com\"]\n",
    "    >>> preprocess(example)\n",
    "    (output:) ['hello love swimming', 'good cook', 'contact']\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    others = [\"'s\", \"the\", \"that\", \"this\", \"to\", \"-PRON-\"]\n",
    "    # I add \"-PRON-\" that erase \"my\", \"your\", etc. other way to erase them is to\n",
    "    #   use adding 'DET' to irrelevant_pos but it would erase the word 'no' too.\n",
    "    for sent in text:\n",
    "        sent = sent.lower()\n",
    "        sent = re.sub(r\"facebook\", \"social media\", sent)\n",
    "        sent = re.sub(r\"twitter\", \"social media\", sent)\n",
    "        sent = re.sub(r\"instagram\", \"social media\", sent)\n",
    "        sent = re.sub(r\"whatsapp\", \"social media\", sent)\n",
    "        sent = re.sub(r\"linkedin\", \"social media\", sent)\n",
    "        sent = re.sub(r\"snapchat\", \"social media\", sent)\n",
    "        result_sent = []\n",
    "        doc = nlp(sent)\n",
    "        entities = [str(ent) for ent in doc.ents if ent.label_ in avoid_entities]\n",
    "        # This helps to detect names of persons, organization and dates\n",
    "        for token in doc:            \n",
    "#             if (token.is_stop == True or\n",
    "            if(token.like_email or\n",
    "                token.like_url or\n",
    "                token.pos_ in irrelevant_pos or\n",
    "                str(token) in entities or\n",
    "                str(token.lemma_) in others or\n",
    "                len(token) < min_token_len):\n",
    "                continue\n",
    "            else:\n",
    "                result_sent.append(token.lemma_)\n",
    "        result.append(\" \".join(result_sent))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(preprocess_comments(data_df_train['Comment']), columns=['Comment'])\n",
    "y_train = np.asarray(data_df_train.drop(columns = ['Comment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = pd.DataFrame(preprocess_comments(data_df_valid['Comment']), columns = ['Comment'])\n",
    "y_valid = np.asarray(data_df_valid.drop(columns = ['Comment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_len(x):\n",
    "    a=x.split()\n",
    "    return len(a)\n",
    "\n",
    "max_len = max(data_df_train['Comment'].apply(max_len))\n",
    "\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12829\n"
     ]
    }
   ],
   "source": [
    "vect=Tokenizer()\n",
    "vect.fit_on_texts(data_df_train['Comment'])\n",
    "vocab_size = len(vect.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('/Users/karan/Downloads/glove/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in vect.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12829, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.18970001,  0.050024  ,  0.19084001, ..., -0.39804   ,\n",
       "         0.47646999, -0.15983   ],\n",
       "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
       "         0.82779998,  0.27061999],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.53812999,  0.72706997,  0.074018  , ..., -0.41005999,\n",
       "         1.08850002,  0.75314999],\n",
       "       [-1.51540005,  0.66566002,  0.23134001, ...,  0.47402   ,\n",
       "         0.84129   ,  0.94787002]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  611   695    48 ...     0     0     0]\n",
      " [  217   114  2027 ...     0     0     0]\n",
      " [  106    75   331 ...     0     0     0]\n",
      " ...\n",
      " [  811    27    45 ...     0     0     0]\n",
      " [  581  3127 12827 ...     0     0     0]\n",
      " [ 1274   701  2303 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "encoded_docs_train = vect.texts_to_sequences(X_train['Comment'])\n",
    "max_length = vocab_size\n",
    "padded_docs_train = pad_sequences(encoded_docs_train, maxlen=max_len, padding='post')\n",
    "print(padded_docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10376, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 127   52 2931 ...    0    0    0]\n",
      " [  15 1930   52 ...    0    0    0]\n",
      " [2457 6774  421 ...    0    0    0]\n",
      " ...\n",
      " [ 148    9  136 ...    0    0    0]\n",
      " [ 322 1139  663 ...    0    0    0]\n",
      " [  78  802 2470 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "encoded_docs_valid = vect.texts_to_sequences(X_valid['Comment'])\n",
    "max_length = vocab_size\n",
    "padded_docs_valid = pad_sequences(encoded_docs_valid, maxlen=max_len, padding='post')\n",
    "print(padded_docs_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2594, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = embedding_matrix.shape[0]\n",
    "maxlen = max_len\n",
    "batch_size = 128\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 2\n",
    "embed_size = 100 # for glove we are using 100d dataset\n",
    "n_class = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 150, 100)          1282900   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 150, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 148, 250)          75250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 74, 250)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 72, 250)           187750    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 36, 250)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 250)               2250250   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 62)                15562     \n",
      "=================================================================\n",
      "Total params: 3,811,712\n",
      "Trainable params: 2,528,812\n",
      "Non-trainable params: 1,282,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, embed_size, weights=[embedding_matrix],\n",
    "                        trainable=False, input_length=maxlen))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters, kernel_size, padding='valid', activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(filters, kernel_size, padding='valid',activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_dims, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_class, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10376 samples, validate on 2594 samples\n",
      "Epoch 1/2\n",
      "10368/10376 [============================>.] - ETA: 0s - loss: 0.1635 - acc: 0.9598 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karan/anaconda3/lib/python3.7/site-packages/numpy/ctypeslib.py:436: RuntimeWarning: Invalid PEP 3118 format string: '&<f'\n",
      "  return array(obj, copy=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10376/10376 [==============================] - 1268s 122ms/step - loss: 0.1634 - acc: 0.9598 - val_loss: 0.1108 - val_acc: 0.9749\n",
      "Epoch 2/2\n",
      "10376/10376 [==============================] - 1294s 125ms/step - loss: 0.1158 - acc: 0.9750 - val_loss: 0.1028 - val_acc: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdc97323490>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(padded_docs_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "          validation_data=(padded_docs_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2594/2594 [==============================] - 240s 93ms/step\n",
      "For threshold:  0.1\n",
      "Micro-average quality numbers\n",
      "Precision: 0.2816, Recall: 0.1203, F1-measure: 0.1686\n",
      "\n",
      "\n",
      "For threshold:  0.2\n",
      "Micro-average quality numbers\n",
      "Precision: 0.6172, Recall: 0.0587, F1-measure: 0.1071\n",
      "\n",
      "\n",
      "For threshold:  0.3\n",
      "Micro-average quality numbers\n",
      "Precision: 0.6747, Recall: 0.0483, F1-measure: 0.0901\n",
      "\n",
      "\n",
      "For threshold:  0.4\n",
      "Micro-average quality numbers\n",
      "Precision: 0.7229, Recall: 0.0413, F1-measure: 0.0782\n",
      "\n",
      "\n",
      "For threshold:  0.5\n",
      "Micro-average quality numbers\n",
      "Precision: 0.7543, Recall: 0.0327, F1-measure: 0.0626\n",
      "\n",
      "\n",
      "For threshold:  0.6\n",
      "Micro-average quality numbers\n",
      "Precision: 0.8087, Recall: 0.0230, F1-measure: 0.0448\n",
      "\n",
      "\n",
      "For threshold:  0.7\n",
      "Micro-average quality numbers\n",
      "Precision: 0.8545, Recall: 0.0116, F1-measure: 0.0230\n",
      "\n",
      "\n",
      "For threshold:  0.8\n",
      "Micro-average quality numbers\n",
      "Precision: 0.9583, Recall: 0.0057, F1-measure: 0.0113\n",
      "\n",
      "\n",
      "For threshold:  0.9\n",
      "Micro-average quality numbers\n",
      "Precision: 1.0000, Recall: 0.0005, F1-measure: 0.0010\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "pred = model.predict(padded_docs_valid, batch_size=batch_size, verbose=1)\n",
    "predictions = pred\n",
    "thresholds=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "for val in thresholds:\n",
    "    print(\"For threshold: \", val)\n",
    "    pred=predictions.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "  \n",
    "    precision = precision_score(y_valid, pred, average='micro')\n",
    "    recall = recall_score(y_valid, pred, average='micro')\n",
    "    f1 = f1_score(y_valid, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Cross Entropy for all Sub-Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfb\n",
    "\n",
    "POS_WEIGHT =  7  # multiplier for positive targets, needs to be tuned\n",
    "\n",
    "def weighted_binary_crossentropy(target, output):\n",
    "    \"\"\"\n",
    "    Weighted binary crossentropy between an output tensor \n",
    "    and a target tensor. POS_WEIGHT is used as a multiplier \n",
    "    for the positive targets.\n",
    "\n",
    "    Combination of the following functions:\n",
    "    * keras.losses.binary_crossentropy\n",
    "    * keras.backend.tensorflow_backend.binary_crossentropy\n",
    "    * tf.nn.weighted_cross_entropy_with_logits\n",
    "    \"\"\"\n",
    "    # transform back to logits\n",
    "    _epsilon = tfb._to_tensor(tfb.epsilon(), output.dtype.base_dtype)\n",
    "    output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n",
    "    output = tf.math.log(output / (1 - output))\n",
    "    # compute weighted loss\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(labels=target,\n",
    "                                                    logits=output,\n",
    "                                                    pos_weight=POS_WEIGHT)\n",
    "    return tf.reduce_mean(loss, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = embedding_matrix.shape[0]\n",
    "maxlen = max_len\n",
    "batch_size = 128\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 2\n",
    "embed_size = 100 # for glove we are using 100d dataset\n",
    "n_class = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 150, 100)          1282900   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 150, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 148, 250)          75250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 74, 250)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 72, 250)           187750    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 36, 250)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 9000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               2250250   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 62)                15562     \n",
      "=================================================================\n",
      "Total params: 3,811,712\n",
      "Trainable params: 2,528,812\n",
      "Non-trainable params: 1,282,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, embed_size, weights=[embedding_matrix],\n",
    "                        trainable=False, input_length=maxlen))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters, kernel_size, padding='valid', activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(filters, kernel_size, padding='valid',activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_dims, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_class, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Value' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-7e75bc222acc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_binary_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 342\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-3d19edb2a9d4>\u001b[0m in \u001b[0;36mweighted_binary_crossentropy\u001b[0;34m(target, output)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\"\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# transform back to logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0m_epsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_epsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0m_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Value' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "model.compile(loss=weighted_binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(padded_docs_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(padded_docs_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "hub_layer = hub.KerasLayer(model, output_shape=[512], input_shape=[], dtype=tf.string, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "inputs2 = tf.keras.layers.Reshape(input_shape=(512,), target_shape=(512, 1))(hub_layer)\n",
    "\n",
    "#embedding1 = Embedding(max_features, 300, weights=[embedding_matrix_fastext], trainable=False)(inputs1)\n",
    "\n",
    "\n",
    "\n",
    "bi_gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(278, return_sequences=True))(inputs2) ## changed from 125\n",
    "global_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_gru)\n",
    "avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_gru)\n",
    "concat_layer = Concatenate()([global_pool, avg_pool])\n",
    "output = tf.keras.Dense(n_class, activation='sigmoid')(concat_layer)\n",
    "model=Model(inputs1, output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'categorical_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_9 (KerasLayer)      (None, 512)          256797824   Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 512, 1)       0           keras_layer_9[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 512, 556)     468708      reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 556)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 556)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1112)         0           global_max_pooling1d_7[0][0]     \n",
      "                                                                 global_average_pooling1d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 62)           69006       concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 257,335,538\n",
      "Trainable params: 257,335,538\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = tf.keras.layers.Input(shape=(), name=\"Input\", dtype=tf.string)\n",
    "x = hub_layer(input)\n",
    "x = tf.keras.layers.Reshape(input_shape=(512,), target_shape=(512, 1))(x)\n",
    "bi_gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(278, return_sequences=True))(x) ## changed from 125\n",
    "global_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_gru)\n",
    "avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_gru)\n",
    "concat_layer = tf.keras.layers.Concatenate()([global_pool, avg_pool])\n",
    "output = tf.keras.layers.Dense(n_class, activation='sigmoid')(concat_layer)\n",
    "model = tf.keras.models.Model(input, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(), name=\"Input\", dtype=tf.string)\n",
    "x = hub_layer(input)\n",
    "x = tf.keras.layers.Reshape(input_shape=(512,), target_shape=(512, 1))(x)\n",
    "x = tf.keras.layers.Conv1D(128, 2, activation='relu', padding='same')(x)\n",
    "x = tf.keras.layers.MaxPooling1D(5, padding='same')(x)\n",
    "x = tf.keras.layers.Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "x = tf.keras.layers.MaxPooling1D(5, padding='same')(x)\n",
    "x = tf.keras.layers.Conv1D(128, 4, activation='relu', padding='same')(x)\n",
    "x = tf.keras.layers.MaxPooling1D(40, padding='same')(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "m = Model(input, output)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def define_model(length, max_features):\n",
    "  # channel 1\n",
    "  inputs1 = Input(shape=(length,))\n",
    "  embedding1 = Embedding(max_features, 300, weights=[embedding_matrix_fastext], trainable=False)(inputs1)\n",
    "  # dropout=SpatialDropout1D(0.2)(embedding1)\n",
    "  bi_gru = Bidirectional(GRU(278, return_sequences=True))(embedding1) ## changed from 125\n",
    "  # bi_gru2 = Bidirectional(GRU(50, return_sequences=True))(bi_gru)\n",
    "  # bi_gru3 = Bidirectional(GRU(50))(bi_gru)\n",
    "  # cnn = Conv1D(filters=120, kernel_size=10, strides=1, padding='valid')(bi_gru2)\n",
    "  global_pool = GlobalMaxPooling1D()(bi_gru)\n",
    "  avg_pool = GlobalAveragePooling1D()(bi_gru)\n",
    "  concat_layer = Concatenate()([global_pool, avg_pool])\n",
    "  output = Dense(n_class, activation='sigmoid')(concat_layer)\n",
    "  model=Model(inputs1, output)\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'categorical_accuracy'])\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = np.asarray(X_train['Comment'])\n",
    "y_train_array = np.asarray(y_train)\n",
    "\n",
    "X_valid_array = np.asarray(X_valid['Comment'])\n",
    "y_valid_array = np.asarray(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10376 samples, validate on 2594 samples\n",
      "Epoch 1/5\n",
      "10376/10376 [==============================] - 346s 33ms/sample - loss: 0.4250 - accuracy: 0.9517 - val_loss: 0.1571 - val_accuracy: 0.9749\n",
      "Epoch 2/5\n",
      "10376/10376 [==============================] - 323s 31ms/sample - loss: 0.1236 - accuracy: 0.9749 - val_loss: 0.1148 - val_accuracy: 0.9749\n",
      "Epoch 3/5\n",
      "10376/10376 [==============================] - 381s 37ms/sample - loss: 0.1122 - accuracy: 0.9749 - val_loss: 0.1107 - val_accuracy: 0.9749\n",
      "Epoch 4/5\n",
      "10376/10376 [==============================] - 361s 35ms/sample - loss: 0.1108 - accuracy: 0.9749 - val_loss: 0.1106 - val_accuracy: 0.9749\n",
      "Epoch 5/5\n",
      "10376/10376 [==============================] - 312s 30ms/sample - loss: 0.1108 - accuracy: 0.9749 - val_loss: 0.1107 - val_accuracy: 0.9749\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_array,\n",
    "                    y_train_array,\n",
    "                    epochs=5,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_valid_array, y_valid_array),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2594/2594 [==============================] - 12s 4ms/sample\n",
      "For threshold:  0.1\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1149, Recall: 0.0738, F1-measure: 0.0898\n",
      "For threshold:  0.2\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.3\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.4\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karan/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.6\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.7\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.8\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.9\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_valid_array, batch_size=512, verbose=1)\n",
    "predictions = pred\n",
    "thresholds=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "for val in thresholds:\n",
    "    print(\"For threshold: \", val)\n",
    "    pred=predictions.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "  \n",
    "    precision = precision_score(y_valid_array, pred, average='micro')\n",
    "    recall = recall_score(y_valid_array, pred, average='micro')\n",
    "    f1 = f1_score(y_valid_array, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer bidirectional_1 was called with an input that isn't a symbolic tensor. Received type: <class 'tensorflow_hub.keras_layer.KerasLayer'>. Full input: [<tensorflow_hub.keras_layer.KerasLayer object at 0x7fdc70789e90>]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/plaidml/keras/backend.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Call the requested function regardless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/plaidml/keras/backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '\n\u001b[0m\u001b[1;32m    928\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'tensorflow_hub.keras_layer.KerasLayer'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-615bd78df022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#embedding1 = Embedding(max_features, 300, weights=[embedding_matrix_fastext], trainable=False)(inputs1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbi_gru\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m278\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## changed from 125\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mglobal_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi_gru\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mavg_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi_gru\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer bidirectional_1 was called with an input that isn't a symbolic tensor. Received type: <class 'tensorflow_hub.keras_layer.KerasLayer'>. Full input: [<tensorflow_hub.keras_layer.KerasLayer object at 0x7fdc70789e90>]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "inputs1 = hub_layer\n",
    "#embedding1 = Embedding(max_features, 300, weights=[embedding_matrix_fastext], trainable=False)(inputs1)\n",
    "bi_gru = Bidirectional(GRU(278, return_sequences=True))(inputs1) ## changed from 125\n",
    "global_pool = GlobalMaxPooling1D()(bi_gru)\n",
    "avg_pool = GlobalAveragePooling1D()(bi_gru)\n",
    "concat_layer = Concatenate()([global_pool, avg_pool])\n",
    "output = Dense(n_class, activation='sigmoid')(concat_layer)\n",
    "model=Model(inputs1, output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'categorical_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_1 (KerasLayer)   (None, 512)               256797824 \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 512, 556)          468708    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 556)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 62)                34534     \n",
      "=================================================================\n",
      "Total params: 257,301,066\n",
      "Trainable params: 257,301,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "x = (hub_layer)\n",
    "x = model.add(tf.keras.layers.Reshape(input_shape=(512,), target_shape=(512, 1)))(x)\n",
    "x = model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(278, return_sequences=True)))(x)\n",
    "\n",
    "y_1 = model.add(tf.keras.layers.GlobalMaxPool1D())(x)\n",
    "y_2 = model.add(tf.keras.layers.GlobalAveragePooling1D())(x)\n",
    "\n",
    "concat_layer = Concatenate()([y_1, y_2])\n",
    "\n",
    "model.add(tf.keras.layers.Dense(n_class, activation = 'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = np.asarray(X_train['Comment'])\n",
    "y_train_array = np.asarray(y_train)\n",
    "\n",
    "X_valid_array = np.asarray(X_valid['Comment'])\n",
    "y_valid_array = np.asarray(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10376 samples, validate on 2594 samples\n",
      "10376/10376 [==============================] - 344s 33ms/sample - loss: 0.4265 - accuracy: 0.9497 - val_loss: 0.1342 - val_accuracy: 0.9749\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_array,\n",
    "                    y_train_array,\n",
    "                    epochs=5,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_valid_array, y_valid_array),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2594/2594 [==============================] - 11s 4ms/sample\n",
      "For threshold:  0.1\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.2\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.3\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karan/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.5\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.6\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.7\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.8\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "For threshold:  0.9\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_valid_array, batch_size=512, verbose=1)\n",
    "predictions = pred\n",
    "thresholds=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "for val in thresholds:\n",
    "    print(\"For threshold: \", val)\n",
    "    pred=predictions.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "  \n",
    "    precision = precision_score(y_valid_array, pred, average='micro')\n",
    "    recall = recall_score(y_valid_array, pred, average='micro')\n",
    "    f1 = f1_score(y_valid_array, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
