{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/interim/undersampling.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>CPD</th>\n",
       "      <th>CB</th>\n",
       "      <th>EWC</th>\n",
       "      <th>Exec</th>\n",
       "      <th>FEW</th>\n",
       "      <th>SP</th>\n",
       "      <th>RE</th>\n",
       "      <th>Sup</th>\n",
       "      <th>SW</th>\n",
       "      <th>TEPE</th>\n",
       "      <th>VMG</th>\n",
       "      <th>OTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To provide training opportunities that align w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create opportunities for SW's to move laterall...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I feel its critical to have ongoing training a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel upset against those supervisors and the s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learn to value and treat auxiliary employees w...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>Transparent work planning. Meeting agendas, ac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>I struggle with some of my answers because I d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>Ensuring that IT issues, access and upgrades a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>A more effective and informed group to support...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>Show a strong stance on the environment, fight...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3283 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  CPD  CB  EWC  Exec  \\\n",
       "0     To provide training opportunities that align w...    1   0    0     0   \n",
       "1     create opportunities for SW's to move laterall...    1   0    0     0   \n",
       "2     I feel its critical to have ongoing training a...    1   0    0     0   \n",
       "3     feel upset against those supervisors and the s...    1   0    0     1   \n",
       "4     Learn to value and treat auxiliary employees w...    1   1    0     0   \n",
       "...                                                 ...  ...  ..  ...   ...   \n",
       "3278  Transparent work planning. Meeting agendas, ac...    0   0    0     0   \n",
       "3279  I struggle with some of my answers because I d...    0   0    0     0   \n",
       "3280  Ensuring that IT issues, access and upgrades a...    0   0    0     0   \n",
       "3281  A more effective and informed group to support...    0   0    0     0   \n",
       "3282  Show a strong stance on the environment, fight...    0   0    0     0   \n",
       "\n",
       "      FEW  SP  RE  Sup  SW  TEPE  VMG  OTH  \n",
       "0       0   0   0    0   0     0    1    0  \n",
       "1       0   1   0    0   0     1    0    0  \n",
       "2       0   0   0    0   0     0    1    0  \n",
       "3       0   0   0    0   0     0    0    0  \n",
       "4       0   0   0    0   0     0    0    0  \n",
       "...   ...  ..  ..  ...  ..   ...  ...  ...  \n",
       "3278    0   0   0    0   0     0    0    1  \n",
       "3279    0   0   0    0   1     0    0    1  \n",
       "3280    0   0   0    0   0     1    0    1  \n",
       "3281    0   0   0    0   0     0    0    1  \n",
       "3282    0   0   0    0   0     0    0    1  \n",
       "\n",
       "[3283 rows x 13 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Comment']\n",
    "y = df.drop(columns=['Comment'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CPD', 'CB', 'EWC', 'Exec', 'FEW', 'SP', 'RE', 'Sup', 'SW', 'TEPE',\n",
       "       'VMG', 'OTH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_names = y.columns\n",
    "themes_ytrain = theme_names\n",
    "themes_ytrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer() \n",
    "X_train = tfid.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2626x7348 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 87009 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.array(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<657x7348 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 20350 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tfid.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parts of code adapated from DSCI 573 lab 4\n",
    "#Dictionary of Base Models\n",
    "\n",
    "models = {\n",
    "    'LinearSVC': LinearSVC(),\n",
    "    'MultinomialNB' : MultinomialNB(),\n",
    "    'GaussianNB' : GaussianNB()#,\n",
    "    #'Random Forest' : RandomForestClassifier(), too slow will use function \n",
    "    #'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    #'Neural Net' : MLPClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For themes only\n",
    "#Note takes about ~15 min to run\n",
    "results_dict_themes = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    classifier_chain = ClassifierChain(model)\n",
    "    \n",
    "    model = classifier_chain.fit(X_train, y_train)\n",
    "    \n",
    "    train = model.score(X_train, y_train)\n",
    "    valid = model.score(X_test, y_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    recall = recall_score(y_test, y_pred, average= 'micro')\n",
    "    precision = precision_score(y_test, y_pred, average= 'micro')\n",
    "    \n",
    "    case= {'Model': model_name,\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}\n",
    "    \n",
    "    results_dict_themes.append(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.948972</td>\n",
       "      <td>0.363775</td>\n",
       "      <td>0.474561</td>\n",
       "      <td>0.743478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.054455</td>\n",
       "      <td>0.024353</td>\n",
       "      <td>0.015726</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.644326</td>\n",
       "      <td>0.048706</td>\n",
       "      <td>0.330250</td>\n",
       "      <td>0.170895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Train Accuracy  Validation Accuracy  Recall Score  \\\n",
       "0      LinearSVC        0.948972             0.363775      0.474561   \n",
       "1  MultinomialNB        0.054455             0.024353      0.015726   \n",
       "2     GaussianNB        0.644326             0.048706      0.330250   \n",
       "\n",
       "   Precision Score  \n",
       "0         0.743478  \n",
       "1         1.000000  \n",
       "2         0.170895  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict_themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEKA Multi-Label Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEKA 1.9.2 found, not downloading\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/karan/scikit_ml_learn_data/meka/meka-release-1.9.2/lib/'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.ext import download_meka\n",
    "from skmultilearn.ext import Meka\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "meka_classpath = download_meka()\n",
    "meka_classpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Meka(java_command='/usr/bin/java',\n",
       "     meka_classifier='meka.classifiers.multilabel.BR',\n",
       "     meka_classpath='/Users/karan/scikit_ml_learn_data/meka/meka-release-1.9.2/lib/',\n",
       "     weka_classifier='weka.classifiers.bayes.NaiveBayesMultinomial')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meka = Meka(\n",
    "        meka_classifier = \"meka.classifiers.multilabel.BR\", # Binary Relevance\n",
    "        weka_classifier = \"weka.classifiers.bayes.NaiveBayesMultinomial\", # with Naive Bayes single-label classifier\n",
    "        meka_classpath = meka_classpath, #obtained via download_meka\n",
    "        java_command = '/usr/bin/java' # path to java executable\n",
    ")\n",
    "meka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Meka(java_command='/usr/bin/java',\n",
       "     meka_classifier='meka.classifiers.multilabel.BR',\n",
       "     meka_classpath='/Users/karan/scikit_ml_learn_data/meka/meka-release-1.9.2/lib/',\n",
       "     weka_classifier='weka.classifiers.bayes.NaiveBayesMultinomial')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meka.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = meka.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1784627092846271"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = meka.score(X_train, y_train)\n",
    "valid = meka.score(X_test, y_test)\n",
    "y_pred = meka.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred, average= 'micro')\n",
    "precision = precision_score(y_test, y_pred, average= 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295506</td>\n",
       "      <td>0.17656</td>\n",
       "      <td>0.360777</td>\n",
       "      <td>0.352622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Accuracy  Validation Accuracy  Recall Score  Precision Score\n",
       "0        0.295506              0.17656      0.360777         0.352622"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}, index=[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Meka(java_command='/usr/bin/java',\n",
       "     meka_classifier='meka.classifiers.multilabel.CC',\n",
       "     meka_classpath='/Users/karan/scikit_ml_learn_data/meka/meka-release-1.9.2/lib/',\n",
       "     weka_classifier='weka.classifiers.meta.AdaBoostM1')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meka = Meka(\n",
    "        meka_classifier = \"meka.classifiers.multilabel.CC\", # Binary Relevance\n",
    "        weka_classifier = \"weka.classifiers.meta.AdaBoostM1\",\n",
    "        meka_classpath = meka_classpath, #obtained via download_meka\n",
    "        java_command = '/usr/bin/java' # path to java executable\n",
    ")\n",
    "meka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "meka.fit(X_train, y_train)\n",
    "predictions = meka.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130998</td>\n",
       "      <td>0.138508</td>\n",
       "      <td>0.235893</td>\n",
       "      <td>0.770393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Accuracy  Validation Accuracy  Recall Score  Precision Score\n",
       "0        0.130998             0.138508      0.235893         0.770393"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = meka.score(X_train, y_train)\n",
    "valid = meka.score(X_test, y_test)\n",
    "y_pred = meka.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred, average= 'micro')\n",
    "precision = precision_score(y_test, y_pred, average= 'micro')\n",
    "pd.DataFrame({\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}, index=[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Meka(java_command='/usr/bin/java',\n",
       "     meka_classifier='meka.classifiers.multilabel.CC',\n",
       "     meka_classpath='/Users/karan/scikit_ml_learn_data/meka/meka-release-1.9.2/lib/',\n",
       "     weka_classifier='weka.classifiers.meta.Bagging')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meka = Meka(\n",
    "        meka_classifier = \"meka.classifiers.multilabel.CC\", # Binary Relevance\n",
    "        weka_classifier = \"weka.classifiers.meta.Bagging\",\n",
    "        meka_classpath = meka_classpath, #obtained via download_meka\n",
    "        java_command = '/usr/bin/java' # path to java executable\n",
    ")\n",
    "meka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-725ad4c2978d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeka\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeka\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/skmultilearn/ext/meka.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    257\u001b[0m             ]\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_meka_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_dump\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_dump_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/skmultilearn/ext/meka.py\u001b[0m in \u001b[0;36m_run_meka_command\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    439\u001b[0m                                  \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                                  universal_newlines=True)\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1713\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "meka.fit(X_train, y_train)\n",
    "predictions = meka.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = meka.score(X_train, y_train)\n",
    "valid = meka.score(X_test, y_test)\n",
    "y_pred = meka.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred, average= 'micro')\n",
    "precision = precision_score(y_test, y_pred, average= 'micro')\n",
    "pd.DataFrame({\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}, index=[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BayesNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Meka(java_command='/usr/bin/java',\n",
       "     meka_classifier='meka.classifiers.multilabel.CC',\n",
       "     meka_classpath='/Users/karan/scikit_ml_learn_data/meka/meka-release-1.9.2/lib/',\n",
       "     weka_classifier='weka.classifiers.bayes.BayesNet')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meka = Meka(\n",
    "        meka_classifier = \"meka.classifiers.multilabel.CC\", # Binary Relevance\n",
    "        weka_classifier = \"weka.classifiers.bayes.BayesNet\",\n",
    "        meka_classpath = meka_classpath, #obtained via download_meka\n",
    "        java_command = '/usr/bin/java' # path to java executable\n",
    ")\n",
    "meka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "meka.fit(X_train, y_train)\n",
    "predictions = meka.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.308835</td>\n",
       "      <td>0.290715</td>\n",
       "      <td>0.53099</td>\n",
       "      <td>0.672131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Accuracy  Validation Accuracy  Recall Score  Precision Score\n",
       "0        0.308835             0.290715       0.53099         0.672131"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = meka.score(X_train, y_train)\n",
    "valid = meka.score(X_test, y_test)\n",
    "y_pred = meka.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred, average= 'micro')\n",
    "precision = precision_score(y_test, y_pred, average= 'micro')\n",
    "pd.DataFrame({\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}, index=[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### meka.classifiers.multilabel.LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Meka(java_command='/usr/bin/java',\n",
       "     meka_classifier='meka.classifiers.multilabel.LC',\n",
       "     meka_classpath='/Users/karan/scikit_ml_learn_data/meka/meka-release-1.9.2/lib/',\n",
       "     weka_classifier=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meka = Meka(\n",
    "        meka_classifier = \"meka.classifiers.multilabel.LC\", # Binary Relevance\n",
    "        #weka_classifier = \"weka.classifiers.bayes.BayesNet\",\n",
    "        meka_classpath = meka_classpath, #obtained via download_meka\n",
    "        java_command = '/usr/bin/java' # path to java executable\n",
    ")\n",
    "meka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "meka.fit(X_train, y_train)\n",
    "predictions = meka.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.624905</td>\n",
       "      <td>0.200913</td>\n",
       "      <td>0.345976</td>\n",
       "      <td>0.395349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Accuracy  Validation Accuracy  Recall Score  Precision Score\n",
       "0        0.624905             0.200913      0.345976         0.395349"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = meka.score(X_train, y_train)\n",
    "valid = meka.score(X_test, y_test)\n",
    "y_pred = meka.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred, average= 'micro')\n",
    "precision = precision_score(y_test, y_pred, average= 'micro')\n",
    "pd.DataFrame({\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}, index=[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D, GlobalMaxPooling1D, MaxPool1D, MaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "#from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import spacy\n",
    "# from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8324\n"
     ]
    }
   ],
   "source": [
    "vect=Tokenizer()\n",
    "vect.fit_on_texts(df['Comment'])\n",
    "vocab_size = len(vect.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('/Users/karan/Downloads/glove/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in vect.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.18970001,  0.050024  ,  0.19084001, ..., -0.39804   ,\n",
       "         0.47646999, -0.15983   ],\n",
       "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
       "         0.82779998,  0.27061999],\n",
       "       ...,\n",
       "       [ 0.64234   ,  0.47938001,  0.39046001, ...,  0.28545001,\n",
       "         0.29418001,  0.37436   ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.17636   ,  0.55317998, -0.31927001, ..., -0.49941   ,\n",
       "         0.58595997, -0.15044001]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Comment']]\n",
    "y = df.drop(columns=['Comment'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_len(x):\n",
    "    a=x.split()\n",
    "    return len(a)\n",
    "\n",
    "max_len = max(df['Comment'].apply(max_len))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 346  551  613 ...    0    0    0]\n",
      " [  90   36 2263 ...    0    0    0]\n",
      " [ 436   18  894 ...    0    0    0]\n",
      " ...\n",
      " [ 697    1   15 ...    0    0    0]\n",
      " [ 643    9   77 ...    0    0    0]\n",
      " [   5  348 8178 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "encoded_docs_train = vect.texts_to_sequences(X_train['Comment'])\n",
    "max_length = vocab_size\n",
    "padded_docs_train = pad_sequences(encoded_docs_train, maxlen=max_len, padding='post')\n",
    "print(padded_docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = embedding_matrix.shape[0]\n",
    "maxlen = max_len\n",
    "batch_size = 128\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 10\n",
    "embed_size = 100 # for glove we are using 100d dataset\n",
    "n_class = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 146, 100)          832400    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 146, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 144, 250)          75250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 72, 250)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 70, 250)           187750    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 35, 250)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8750)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 250)               2187750   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 12)                3012      \n",
      "=================================================================\n",
      "Total params: 3,286,162\n",
      "Trainable params: 2,453,762\n",
      "Non-trainable params: 832,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, embed_size, weights=[embedding_matrix],\n",
    "                        trainable=False, input_length=maxlen))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filters, kernel_size, padding='valid', activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(filters, kernel_size, padding='valid',activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_dims, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(n_class, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karan/anaconda3/lib/python3.7/site-packages/numpy/ctypeslib.py:436: RuntimeWarning: Invalid PEP 3118 format string: '&<q'\n",
      "  return array(obj, copy=False)\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2626/2626 [==============================] - 59s 23ms/step - loss: 0.7155 - acc: 0.8332\n",
      "Epoch 2/5\n",
      "2626/2626 [==============================] - 55s 21ms/step - loss: 0.4051 - acc: 0.8596\n",
      "Epoch 3/5\n",
      "2626/2626 [==============================] - 55s 21ms/step - loss: 0.4019 - acc: 0.8596\n",
      "Epoch 4/5\n",
      "2626/2626 [==============================] - 55s 21ms/step - loss: 0.3970 - acc: 0.8598\n",
      "Epoch 5/5\n",
      "2626/2626 [==============================] - 55s 21ms/step - loss: 0.3784 - acc: 0.8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2995aaf10>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(padded_docs_train, y_train, batch_size=batch_size, epochs=5, class_weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating padded dataset for x_valid\n",
    "encoded_docs_valid = vect.texts_to_sequences(X_test['Comment'])\n",
    "padded_docs_valid = pad_sequences(encoded_docs_valid, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 15s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38082090328636053, 0.8675799322636342]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(padded_docs_valid,y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 16s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(padded_docs_valid, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17814445, 0.19023477, 0.11674318, ..., 0.8478421 , 0.21039556,\n",
       "        0.18262035],\n",
       "       [0.04306564, 0.19953047, 0.05309377, ..., 0.11371254, 0.01344639,\n",
       "        0.0858386 ],\n",
       "       [0.09085   , 0.12003379, 0.05861139, ..., 0.26561162, 0.17625782,\n",
       "        0.12425753],\n",
       "       ...,\n",
       "       [0.05833021, 0.13478012, 0.04545392, ..., 0.08720328, 0.01749544,\n",
       "        0.11164635],\n",
       "       [0.02363847, 0.02747857, 0.02640555, ..., 0.81004304, 0.02224762,\n",
       "        0.07692412],\n",
       "       [0.16842692, 0.10970025, 0.11133917, ..., 0.03868888, 0.20595995,\n",
       "        0.10622642]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For threshold:  0.1\n",
      "Micro-average quality numbers\n",
      "Precision: 0.1709, Recall: 0.8196, F1-measure: 0.2829\n",
      "\n",
      "\n",
      "For threshold:  0.2\n",
      "Micro-average quality numbers\n",
      "Precision: 0.2347, Recall: 0.4246, F1-measure: 0.3023\n",
      "\n",
      "\n",
      "For threshold:  0.3\n",
      "Micro-average quality numbers\n",
      "Precision: 0.2975, Recall: 0.1841, F1-measure: 0.2274\n",
      "\n",
      "\n",
      "For threshold:  0.4\n",
      "Micro-average quality numbers\n",
      "Precision: 0.4545, Recall: 0.0925, F1-measure: 0.1537\n",
      "\n",
      "\n",
      "For threshold:  0.5\n",
      "Micro-average quality numbers\n",
      "Precision: 0.6796, Recall: 0.0648, F1-measure: 0.1182\n",
      "\n",
      "\n",
      "For threshold:  0.6\n",
      "Micro-average quality numbers\n",
      "Precision: 0.7625, Recall: 0.0564, F1-measure: 0.1051\n",
      "\n",
      "\n",
      "For threshold:  0.7\n",
      "Micro-average quality numbers\n",
      "Precision: 0.8060, Recall: 0.0500, F1-measure: 0.0941\n",
      "\n",
      "\n",
      "For threshold:  0.8\n",
      "Micro-average quality numbers\n",
      "Precision: 0.8269, Recall: 0.0398, F1-measure: 0.0759\n",
      "\n",
      "\n",
      "For threshold:  0.9\n",
      "Micro-average quality numbers\n",
      "Precision: 0.8667, Recall: 0.0241, F1-measure: 0.0468\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "predictions = pred\n",
    "thresholds=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "for val in thresholds:\n",
    "    print(\"For threshold: \", val)\n",
    "    pred=predictions.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "  \n",
    "    precision = precision_score(y_test, pred, average='micro')\n",
    "    recall = recall_score(y_test, pred, average='micro')\n",
    "    f1 = f1_score(y_test, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM using Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 146, 100)          832400    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 146, 120)          106080    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 146, 120)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                47360     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 988,316\n",
      "Trainable params: 155,916\n",
      "Non-trainable params: 832,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Configuring the parameters\n",
    "model.add(Embedding(max_features, 100, input_length=max_len, weights=[embedding_matrix], trainable=False))\n",
    "\n",
    "model.add(LSTM(120, return_sequences=True))  \n",
    "\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(n_class, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1905 of 28322 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 6663 of 28322 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 11109 of 28322 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 18410 of 28322 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 24215 of 28322 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2626 [============================>.] - ETA: 2s - loss: 1.9596 - acc: 0.1209"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m_ctypes/callbacks.c\u001b[0m in \u001b[0;36m'calling callback function'\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/plaidml/library.py\u001b[0m in \u001b[0;36m_logger_callback\u001b[0;34m(self, unused_arg, level, msg)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_logger_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mseverity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LOG_SEVERITY_MAP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseverity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 7102 of 28322 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 11518 of 28322 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 17816 of 28322 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 24034 of 28322 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2626/2626 [==============================] - 153s 58ms/step - loss: 1.9641 - acc: 0.1178\n",
      "Epoch 2/2\n",
      "2626/2626 [==============================] - 64s 24ms/step - loss: 2.2628 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2e4ca0990>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(padded_docs_train, y_train, batch_size=batch_size, epochs=2, class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = class_weight.compute_sample_weight('balanced', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
