{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D, GlobalMaxPooling1D, MaxPool1D, MaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import spacy\n",
    "# from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Q1 = pd.read_excel('../data/interim/X_train_Q1_clean.xlsx')\n",
    "X_valid_Q1 = pd.read_excel('../data/interim/X_valid_Q1_clean.xlsx')\n",
    "\n",
    "y_train_Q1 = pd.read_excel('../data/interim/y_train_Q1.xlsx')\n",
    "y_valid_Q1 = pd.read_excel('../data/interim/y_valid_Q1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "# function adapted from `preprocess` function of lab 3 \n",
    "# of this course (575 Advance Learning Machine)\n",
    "def preprocess_comments(text, \n",
    "                        min_token_len = 2, \n",
    "                        irrelevant_pos = ['PRON', 'SPACE', 'PUNCT', 'ADV', \n",
    "                                          'ADP', 'CCONJ', 'AUX', 'PRP'],\n",
    "                        avoid_entities = ['PERSON', 'ORG', 'LOC', 'GPE']):\n",
    "# note: Didn't use the following options in the `preprocess_comments`...\n",
    "#    - 'PROPN' because it erases proper names as 'George', but also words as orange.\n",
    "#    - 'DET' since it removes the word 'no', which changes the meaning of a sentence.\n",
    "# *for more information see link: https://universaldependencies.org/u/pos/\n",
    "    \"\"\"\n",
    "    Given text, min_token_len, irrelevant_pos and avoid_entities, carries out \n",
    "    preprocessing of the text and returns list of preprocessed text. \n",
    "    Parameters\n",
    "    -------------\n",
    "    text : (list) \n",
    "        the list of text to be preprocessed\n",
    "    min_token_len : (int) \n",
    "        min_token_length required\n",
    "    irrelevant_pos : (list) \n",
    "        a list of irrelevant pos tags\n",
    "    avoid_entities : (list)\n",
    "        a list of entity labels to be avoided\n",
    "    Returns\n",
    "    -------------\n",
    "    (list) list of preprocessed text\n",
    "    Example\n",
    "    -------------\n",
    "    >>> example = [\"Hello, I'm George and I love swimming!\",\n",
    "                   \"I am a really good cook; what about you?\",\n",
    "                   \"Contact me at george23@gmail.com\"]\n",
    "    >>> preprocess(example)\n",
    "    (output:) ['hello love swimming', 'good cook', 'contact']\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    others = [\"'s\", \"the\", \"that\", \"this\", \"to\", \"-PRON-\"]\n",
    "    # I add \"-PRON-\" that erase \"my\", \"your\", etc. other way to erase them is to\n",
    "    #   use adding 'DET' to irrelevant_pos but it would erase the word 'no' too.\n",
    "    for sent in text:\n",
    "        sent = sent.lower()\n",
    "        sent = re.sub(r\"facebook\", \"social media\", sent)\n",
    "        sent = re.sub(r\"twitter\", \"social media\", sent)\n",
    "        sent = re.sub(r\"instagram\", \"social media\", sent)\n",
    "        sent = re.sub(r\"whatsapp\", \"social media\", sent)\n",
    "        sent = re.sub(r\"linkedin\", \"social media\", sent)\n",
    "        sent = re.sub(r\"snapchat\", \"social media\", sent)\n",
    "        result_sent = []\n",
    "        doc = nlp(sent)\n",
    "        entities = [str(ent) for ent in doc.ents if ent.label_ in avoid_entities]\n",
    "        # This helps to detect names of persons, organization and dates\n",
    "        for token in doc:            \n",
    "#             if (token.is_stop == True or\n",
    "            if(token.like_email or\n",
    "                token.like_url or\n",
    "                token.pos_ in irrelevant_pos or\n",
    "                str(token) in entities or\n",
    "                str(token.lemma_) in others or\n",
    "                len(token) < min_token_len):\n",
    "                continue\n",
    "            else:\n",
    "                result_sent.append(token.lemma_)\n",
    "        result.append(\" \".join(result_sent))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = pd.read_csv('data/X_valid.csv')\n",
    "\n",
    "preprocessed_x_train = preprocessing.preprocess_comments(X_train['Comment'])\n",
    "preprocessed_x_valid = preprocessing.preprocess_comments(X_valid['Comment'])\n",
    "\n",
    "\n",
    "X_train_ppd = pd.DataFrame(preprocessed_x_train, columns=['Comment'])\n",
    "X_valid_ppd = pd.DataFrame(preprocessed_x_valid, columns=['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X_train_Q1, y_train_Q1.iloc[:,:12]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>CPD</th>\n",
       "      <th>CB</th>\n",
       "      <th>EWC</th>\n",
       "      <th>Exec</th>\n",
       "      <th>FEW</th>\n",
       "      <th>SP</th>\n",
       "      <th>RE</th>\n",
       "      <th>Sup</th>\n",
       "      <th>SW</th>\n",
       "      <th>TEPE</th>\n",
       "      <th>VMG</th>\n",
       "      <th>OTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to be real about diversity, you need to create...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keep the building warmer and provide warm wate...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>better communication from the top down</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It would be beneficial if Management did not m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>more education applicable to my job</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  CPD  CB  EWC  Exec  FEW  \\\n",
       "0  to be real about diversity, you need to create...    0   0    1     0    0   \n",
       "1  Keep the building warmer and provide warm wate...    0   0    0     0    0   \n",
       "2             better communication from the top down    0   0    0     1    0   \n",
       "3  It would be beneficial if Management did not m...    0   0    0     0    0   \n",
       "4                more education applicable to my job    1   0    0     0    0   \n",
       "\n",
       "   SP  RE  Sup  SW  TEPE  VMG  OTH  \n",
       "0   0   0    0   0     0    0    0  \n",
       "1   0   0    0   0     1    0    0  \n",
       "2   0   0    0   0     0    0    0  \n",
       "3   0   1    0   0     0    0    0  \n",
       "4   0   0    0   0     0    0    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ppd = pd.DataFrame(preprocess_comments(df['Comment']), columns=['Comment'])\n",
    "X_valid_ppd = pd.DataFrame(preprocess_comments(df['Comment']), columns=['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real diversity need create seat table mean aff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>keep building warm provide warm water bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well communication top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would beneficial if management not micro manage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>more education applicable job</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment\n",
       "0  real diversity need create seat table mean aff...\n",
       "1     keep building warm provide warm water bathroom\n",
       "2                             well communication top\n",
       "3    would beneficial if management not micro manage\n",
       "4                      more education applicable job"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ppd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_len(x):\n",
    "    a=x.split()\n",
    "    return len(a)\n",
    "max_len = max(X_train_ppd['Comment'].apply(max_len))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8638\n"
     ]
    }
   ],
   "source": [
    "vect=Tokenizer()\n",
    "vect.fit_on_texts(X_train_ppd['Comment'])\n",
    "vocab_size = len(vect.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1999996 word vectors\n"
     ]
    }
   ],
   "source": [
    "embeddings_matrix = {}\n",
    "f = codecs.open('/Users/karan/Downloads/crawl-300d-2M.vec', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.rstrip().rsplit(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_matrix[word] = coefs\n",
    "f.close()\n",
    "print('found %s word vectors' % len(embeddings_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix_fastext = np.zeros((vocab_size, 300))\n",
    "for word, i in vect.word_index.items():\n",
    "    embedding_vector = embeddings_matrix.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix_fastext[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../models/embedding_matrix_fastext_ppd', embedding_matrix_fastext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
