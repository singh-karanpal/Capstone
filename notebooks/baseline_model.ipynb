{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model for Question 1 (data from 2013, 2018, 2020)\n",
    "## Multi-Label Classification using Classifier Chains model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is after importing preprocessing comments**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#### This code is from preprocessing to be used before \n",
    "#### running code below to create clean texts for fitting \n",
    "#----------------------------------------------------------------\n",
    "\n",
    "# #Create class object\n",
    "# c_pp = comment_preprocessor()\n",
    "\n",
    "# #clean X training set\n",
    "# clean_doc_train, vocab_train = c_pp.preprocess_text(list(X_train_Q1['Comment']))\n",
    "# #clean X valid\n",
    "# clean_doc_valid, vocab_valid = c_pp.preprocess_text(list(X_valid_Q1['Comment']))\n",
    "\n",
    "# ## For baseline, convert list of lists into list of sentences using the following code\n",
    "\n",
    "# clean_text = []\n",
    "# for docs in clean_doc_train:\n",
    "#     clean_text.append(' '.join(docs)) \n",
    "\n",
    "# #save clean text \n",
    "# X_train_Q1['clean_text'] = clean_text\n",
    "# X_train_Q1.to_csv('data/X_train_Q1_clean.csv', index=False)\n",
    "\n",
    "# #validation set preprocess\n",
    "# clean_text_val = []\n",
    "# for docs in clean_doc_valid:\n",
    "#     clean_text_val.append(' '.join(docs))\n",
    "\n",
    "# #save valid clean text \n",
    "# X_valid_Q1['clean_text'] = clean_text_val\n",
    "# X_valid_Q1.to_csv('data/X_valid_Q1_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in preprocessed train and validation datas\n",
    "#your path here\n",
    "\n",
    "X_train_Q1 = pd.read_csv('data/X_train_Q1_clean.csv')\n",
    "X_valid_Q1 = pd.read_csv('data/X_valid_Q1_clean.csv')\n",
    "\n",
    "y_train_Q1 = pd.read_csv('data/y_train_Q1.csv')\n",
    "y_valid_Q1 = pd.read_csv('data/y_valid_Q1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfid Vectorizer Representation\n",
    "First we'll use Tfid as vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfid Vectorizer Representation\n",
    "\n",
    "def tfid_vectorizer(train, valid):\n",
    "    \"\"\"\n",
    "    Fits the TfidVectorizer() on your X training \n",
    "    set and transform on X validation set\n",
    "    Returns the matrixes.\n",
    "    \"\"\"\n",
    "    tfid = TfidfVectorizer() \n",
    "    X = tfid.fit_transform(train)\n",
    "    X_valid = tfid.transform(valid)\n",
    "    return X, X_valid\n",
    "\n",
    "\n",
    "#To view the representation\n",
    "#bow = pd.DataFrame(X_train_tfid, columns=sorted(tfid.vocabulary_), index=final_comments)\n",
    "#bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize X_train and convert Y_train to an array\n",
    "\n",
    "X_train, X_valid = tfid_vectorizer(X_train_Q1['clean_text'].values.astype('U'), \n",
    "                                    X_valid_Q1['clean_text'].values.astype('U')) #had to convert type \n",
    "#ytrain for all themes and subthemes\n",
    "Y_train = (np.array(y_train_Q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme columns: 13\n",
      "Subtheme columns: 62\n"
     ]
    }
   ],
   "source": [
    "#slice y to themes and subthemes\n",
    "#y_train\n",
    "subthemes_ytrain = y_train_Q1.loc[:, 'CPD_Improve_new_employee_orientation':'OTH_Covid']\n",
    "themes_ytrain = y_train_Q1[['CPD','CB', 'EWC', 'Exec', 'FEW', 'SP', 'RE', 'Sup', 'SW', 'TEPE',\n",
    "                            'VMG', 'OTH', 'Unrelated']]\n",
    "\n",
    "#y_valid\n",
    "subthemes_yvalid = y_valid_Q1.loc[:, 'CPD_Improve_new_employee_orientation':'OTH_Covid']\n",
    "themes_yvalid = y_valid_Q1[['CPD','CB', 'EWC', 'Exec', 'FEW', 'SP', 'RE', 'Sup', \n",
    "                                      'SW', 'TEPE','VMG', 'OTH', 'Unrelated']]\n",
    "\n",
    "#shape check: 13 themes and 62 subthemes\n",
    "print('Theme columns:',themes_ytrain.shape[1])\n",
    "print('Subtheme columns:', subthemes_ytrain.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2594, 62)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(subthemes_yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2594, 13)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(themes_yvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Chain\n",
    "## Subthemes only\n",
    "### trying different models to choose best baseline classifier\n",
    "\n",
    "**Starting with Subthemes Y only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parts of code adapated from DSCI 573 lab 4\n",
    "#Dictionary of Base Models\n",
    "\n",
    "models = {\n",
    "    'LinearSVC': LinearSVC(),\n",
    "    'MultinomialNB' : MultinomialNB(),\n",
    "    'GaussianNB' : GaussianNB()#,\n",
    "    #'Random Forest' : RandomForestClassifier(), too slow will use function \n",
    "    #'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    #'Neural Net' : MLPClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For subthemes only\n",
    "#Note takes about 15 min to run\n",
    "\n",
    "results_dict = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    classifier_chain = ClassifierChain(model)\n",
    "    model = classifier_chain.fit(X_train, subthemes_ytrain)\n",
    "    train = model.score(X_train, np.array(subthemes_ytrain))\n",
    "    valid = model.score(X_valid, np.array(subthemes_yvalid))\n",
    "    y_pred = model.predict(X_valid)\n",
    "    recall = recall_score(np.array(subthemes_yvalid), y_pred, average= 'micro')\n",
    "    precision = precision_score(np.array(subthemes_yvalid), y_pred, average= 'micro')\n",
    "    \n",
    "    case= {'Model': model_name,\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}\n",
    "    \n",
    "    results_dict.append(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.798670</td>\n",
       "      <td>0.328065</td>\n",
       "      <td>0.403465</td>\n",
       "      <td>0.709312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.043562</td>\n",
       "      <td>0.034901</td>\n",
       "      <td>0.933775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.448921</td>\n",
       "      <td>0.024672</td>\n",
       "      <td>0.291584</td>\n",
       "      <td>0.074228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Train Accuracy  Validation Accuracy  Recall Score  \\\n",
       "0      LinearSVC        0.798670             0.328065      0.403465   \n",
       "1  MultinomialNB        0.051850             0.043562      0.034901   \n",
       "2     GaussianNB        0.448921             0.024672      0.291584   \n",
       "\n",
       "   Precision Score  \n",
       "0         0.709312  \n",
       "1         0.933775  \n",
       "2         0.074228  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inital look at df\n",
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list-dictionary of basemodels\n",
    "results_dict2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier_Chain(Ytrain, Yvalid, base_model):\n",
    "    \"\"\"\n",
    "    Fits a Classifier Chain Model with the base classifier of choice and \n",
    "    using either themes or subthemes Y.\n",
    "    Show results of training accuracy score, validation accuracy score, \n",
    "    validation recall and precision scores.\n",
    "    \"\"\"\n",
    "    classifier_chain = ClassifierChain(base_model)\n",
    "    \n",
    "    model = classifier_chain.fit(X_train, subthemes_ytrain)\n",
    "    train = model.score(X_train, np.array(subthemes_ytrain))\n",
    "    valid = model.score(X_valid, np.array(subthemes_yvalid))\n",
    "    y_pred = model.predict(X_valid)\n",
    "    recall = recall_score(np.array(subthemes_yvalid), y_pred, average= 'micro')\n",
    "    precision = precision_score(np.array(subthemes_yvalid), y_pred, average= 'micro')\n",
    "    \n",
    "    case= {'Model': base_model,\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}\n",
    "    \n",
    "    results_dict2.append(case)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Model': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=None, oob_score=False, random_state=None,\n",
       "                         verbose=0, warm_start=False),\n",
       "  'Train Accuracy': 0.9966268311488049,\n",
       "  'Validation Accuracy': 0.19082498072474943,\n",
       "  'Recall Score': 0.1948019801980198,\n",
       "  'Precision Score': 0.8619934282584885}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest' : RandomForestClassifier()\n",
    "#Note takes quite some time ~15 min on my computer\n",
    "Classifier_Chain(subthemes_ytrain, subthemes_yvalid, RandomForestClassifier())\n",
    "results_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict2[0]['Model'] = 'RandomForest' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Model': 'RandomForest',\n",
       "  'Train Accuracy': 0.9966268311488049,\n",
       "  'Validation Accuracy': 0.19082498072474943,\n",
       "  'Recall Score': 0.1948019801980198,\n",
       "  'Precision Score': 0.8619934282584885},\n",
       " {'Model': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                         max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                         random_state=None, splitter='best'),\n",
       "  'Train Accuracy': 0.9979760986892829,\n",
       "  'Validation Accuracy': 0.22629144178874325,\n",
       "  'Recall Score': 0.4373762376237624,\n",
       "  'Precision Score': 0.4723336006415397}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree' : DecisionTreeClassifier()\n",
    "#Note takes quite some time ~15 min on my computer\n",
    "Classifier_Chain(subthemes_ytrain, subthemes_yvalid, DecisionTreeClassifier())\n",
    "results_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict2[1]['Model'] = 'DecisionTree' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearSVC(multi_class= \"crammer_singer\")\n",
    "#\"crammer_singer\" optimizes a joint objective over all classes.\n",
    "Classifier_Chain(subthemes_ytrain, subthemes_yvalid, LinearSVC(multi_class= \"crammer_singer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict2[2]['Model'] = 'LinearSVC(multi_class= \"crammer_singer\")' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying last year's base classifier LinearSVC(C=0.5, tol=0.2)\n",
    "\n",
    "results_dict2 = []\n",
    "Classifier_Chain(subthemes_ytrain, subthemes_yvalid, LinearSVC(C=0.5, tol=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict2[3]['Model'] = 'LinearSVC(C=0.5, tol=0.2) 2019 capstone base' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict.extend(results_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.798670</td>\n",
       "      <td>0.328065</td>\n",
       "      <td>0.403465</td>\n",
       "      <td>0.709312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.043562</td>\n",
       "      <td>0.034901</td>\n",
       "      <td>0.933775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.448921</td>\n",
       "      <td>0.024672</td>\n",
       "      <td>0.291584</td>\n",
       "      <td>0.074228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.996627</td>\n",
       "      <td>0.190825</td>\n",
       "      <td>0.194802</td>\n",
       "      <td>0.861993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.997976</td>\n",
       "      <td>0.226291</td>\n",
       "      <td>0.437376</td>\n",
       "      <td>0.472334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC(multi_class= \"crammer_singer\")</td>\n",
       "      <td>0.707209</td>\n",
       "      <td>0.343099</td>\n",
       "      <td>0.424010</td>\n",
       "      <td>0.655067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC(C=0.5, tol=0.2) 2019 capstone base</td>\n",
       "      <td>0.562355</td>\n",
       "      <td>0.315343</td>\n",
       "      <td>0.372772</td>\n",
       "      <td>0.758308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model  Train Accuracy  \\\n",
       "0                                     LinearSVC        0.798670   \n",
       "1                                 MultinomialNB        0.051850   \n",
       "2                                    GaussianNB        0.448921   \n",
       "3                                  RandomForest        0.996627   \n",
       "4                                  DecisionTree        0.997976   \n",
       "5      LinearSVC(multi_class= \"crammer_singer\")        0.707209   \n",
       "6  LinearSVC(C=0.5, tol=0.2) 2019 capstone base        0.562355   \n",
       "\n",
       "   Validation Accuracy  Recall Score  Precision Score  \n",
       "0             0.328065      0.403465         0.709312  \n",
       "1             0.043562      0.034901         0.933775  \n",
       "2             0.024672      0.291584         0.074228  \n",
       "3             0.190825      0.194802         0.861993  \n",
       "4             0.226291      0.437376         0.472334  \n",
       "5             0.343099      0.424010         0.655067  \n",
       "6             0.315343      0.372772         0.758308  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_results =pd.DataFrame(results_dict)\n",
    "my_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***All models overfitting especially the Tree models. Best one overall is LinearSVC with default multi-class='ovr'. Still overfitting though, try tune regularization (less regularization is larger C)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping through various C value in LinearSVC\n",
    "\n",
    "scores = []\n",
    "for i in (10.0**np.arange(-4,4)):\n",
    "    model = ClassifierChain(LinearSVC(C = i, max_iter = 100000)).fit(X_train, subthemes_ytrain)\n",
    "    #train = model.score(X_train, np.array(subthemes_ytrain))\n",
    "    valid = model.score(X_valid, np.array(subthemes_yvalid))\n",
    "    \n",
    "    scores.append(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10.0**np.arange(-4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0007710100231303007,\n",
       " 0.0007710100231303007,\n",
       " 0.04741711642251349,\n",
       " 0.2459521973785659,\n",
       " 0.32806476484194297,\n",
       " 0.2848882035466461,\n",
       " 0.2579028527370856,\n",
       " 0.24710871241326138]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Regularization doesn't help here. The best validation score is given by the default C hyperparameter = 1.0. Let's try this on LinearSVC(multi-class='crammer_singer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping through various C value in LinearSVC multiclass= crammer_singer \n",
    "\n",
    "scores = []\n",
    "for i in (10.0**np.arange(-4,4)):\n",
    "    model = ClassifierChain(LinearSVC(multi_class= \"crammer_singer\", C = i, max_iter = 100000)).fit(X_train, subthemes_ytrain)\n",
    "    #train = model.score(X_train, np.array(subthemes_ytrain))\n",
    "    valid = model.score(X_valid, np.array(subthemes_yvalid))\n",
    "    \n",
    "    scores.append(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0007710100231303007,\n",
       " 0.0007710100231303007,\n",
       " 0.009252120277563608,\n",
       " 0.19275250578257516,\n",
       " 0.3430994602929838,\n",
       " 0.2679259830377795,\n",
       " 0.25212027756360833,\n",
       " 0.24710871241326138]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Same results for C values of crammer_singer. Seems that Linear(SVC) with its default regularization gives the highest\n",
    "\n",
    "> Due to lack of resources could not find proper way to GridSeach with multilabel classifier. https://stackoverflow.com/questions/26018543/gridsearch-for-multi-label-classification-in-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearSVC': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "           intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "           multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "           verbose=0),\n",
       " 'MultinomialNB': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " 'GaussianNB': GaussianNB(priors=None, var_smoothing=1e-09)}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For themes Y \n",
    "\n",
    "## working the same steps on Themes to find base classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For themes only\n",
    "#Note takes about ~15 min to run\n",
    "results_dict_themes = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    classifier_chain = ClassifierChain(model)\n",
    "    model = classifier_chain.fit(X_train, themes_ytrain)\n",
    "    train = model.score(X_train, np.array(themes_ytrain))\n",
    "    valid = model.score(X_valid, np.array(themes_yvalid))\n",
    "    y_pred = model.predict(X_valid)\n",
    "    recall = recall_score(np.array(themes_yvalid), y_pred, average= 'micro')\n",
    "    precision = precision_score(np.array(themes_yvalid), y_pred, average= 'micro')\n",
    "    \n",
    "    case= {'Model': model_name,\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}\n",
    "    \n",
    "    results_dict_themes.append(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.816596</td>\n",
       "      <td>0.484194</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.759259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.246338</td>\n",
       "      <td>0.205860</td>\n",
       "      <td>0.175235</td>\n",
       "      <td>0.949102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.363724</td>\n",
       "      <td>0.049730</td>\n",
       "      <td>0.588447</td>\n",
       "      <td>0.143599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Train Accuracy  Validation Accuracy  Recall Score  \\\n",
       "0      LinearSVC        0.816596             0.484194      0.611940   \n",
       "1  MultinomialNB        0.246338             0.205860      0.175235   \n",
       "2     GaussianNB        0.363724             0.049730      0.588447   \n",
       "\n",
       "   Precision Score  \n",
       "0         0.759259  \n",
       "1         0.949102  \n",
       "2         0.143599  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict_themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty out list\n",
    "results_dict3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier_Chain(Ytrain, Yvalid, base_model):\n",
    "    \"\"\"\n",
    "    Fits a Classifier Chain Model with the base classifier of choice and \n",
    "    using either themes or subthemes Y.\n",
    "    Show results of training accuracy score, validation accuracy score, \n",
    "    validation recall and precision scores.\n",
    "    \"\"\"\n",
    "    classifier_chain = ClassifierChain(base_model)\n",
    "    \n",
    "    model = classifier_chain.fit(X_train, themes_ytrain) #subthemes_ytrain)\n",
    "    train = model.score(X_train, np.array(themes_ytrain)) #subthemes_ytrain\n",
    "    valid = model.score(X_valid, np.array(themes_yvalid)) #subthemes_yvalid\n",
    "    y_pred = model.predict(X_valid)\n",
    "    recall = recall_score(np.array(themes_yvalid), y_pred, average= 'micro') #subthemes_yvalid\n",
    "    precision = precision_score(np.array(themes_yvalid), y_pred, average= 'micro') #subthemes_yvalid\n",
    "    \n",
    "    case= {'Model': base_model,\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}\n",
    "    \n",
    "    #print(case)\n",
    "    results_dict3.append(case)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest' : RandomForestClassifier()\n",
    "#Note takes quite some time ~15 min on my computer\n",
    "Classifier_Chain(themes_ytrain, themes_yvalid, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict3[0]['Model'] = 'RandomForest' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree' : DecisionTreeClassifier()\n",
    "#Note takes quite some time ~15 min on my computer\n",
    "Classifier_Chain(themes_ytrain, themes_yvalid, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict3[1]['Model'] = 'DecisionTree' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearSVC(multi_class= \"crammer_singer\")\n",
    "#\"crammer_singer\" optimizes a joint objective over all classes.\n",
    "Classifier_Chain(themes_ytrain, themes_yvalid, LinearSVC(multi_class= \"crammer_singer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict3[2]['Model'] = 'LinearSVC(multi_class= \"crammer_singer\")' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_themes.extend(results_dict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.816596</td>\n",
       "      <td>0.484194</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.759259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.246338</td>\n",
       "      <td>0.205860</td>\n",
       "      <td>0.175235</td>\n",
       "      <td>0.949102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.363724</td>\n",
       "      <td>0.049730</td>\n",
       "      <td>0.588447</td>\n",
       "      <td>0.143599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.998554</td>\n",
       "      <td>0.427525</td>\n",
       "      <td>0.466556</td>\n",
       "      <td>0.857724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.998554</td>\n",
       "      <td>0.371241</td>\n",
       "      <td>0.604478</td>\n",
       "      <td>0.606826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC(multi_class= \"crammer_singer\")</td>\n",
       "      <td>0.757806</td>\n",
       "      <td>0.492290</td>\n",
       "      <td>0.624378</td>\n",
       "      <td>0.716688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Train Accuracy  \\\n",
       "0                                 LinearSVC        0.816596   \n",
       "1                             MultinomialNB        0.246338   \n",
       "2                                GaussianNB        0.363724   \n",
       "3                              RandomForest        0.998554   \n",
       "4                              DecisionTree        0.998554   \n",
       "5  LinearSVC(multi_class= \"crammer_singer\")        0.757806   \n",
       "\n",
       "   Validation Accuracy  Recall Score  Precision Score  \n",
       "0             0.484194      0.611940         0.759259  \n",
       "1             0.205860      0.175235         0.949102  \n",
       "2             0.049730      0.588447         0.143599  \n",
       "3             0.427525      0.466556         0.857724  \n",
       "4             0.371241      0.604478         0.606826  \n",
       "5             0.492290      0.624378         0.716688  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict_themes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For themes, also looks like LinearSVC() is the best. Hypothesizing that the best regularization parameter C for this model is their default values. Let's see if regularizing Decision Tree will help with overfitting and get better validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping through various max_depth value in LinearSVC multiclass= crammer_singer \n",
    "\n",
    "scores = []\n",
    "for i in range(10,100,10):\n",
    "    model = ClassifierChain(DecisionTreeClassifier(max_depth = i)).fit(X_train, themes_ytrain)\n",
    "    #train = model.score(X_train, np.array(subthemes_ytrain))\n",
    "    valid = model.score(X_valid, np.array(themes_yvalid))\n",
    "    \n",
    "    scores.append(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3797224363916731,\n",
       " 0.4055512721665382,\n",
       " 0.4109483423284503,\n",
       " 0.40670778720123363,\n",
       " 0.3982266769468003,\n",
       " 0.40400925212027755,\n",
       " 0.39552814186584423,\n",
       " 0.39167309175019277,\n",
       " 0.38781804163454126]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Looks like none of these max depths improves the validation accuracy with None of result 0.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset list\n",
    "results_dict3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying last year's base classifier LinearSVC(C=0.5, tol=0.2)\n",
    "Classifier_Chain(themes_ytrain, themes_yvalid, LinearSVC(C=0.5, tol=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict3[0]['Model'] = 'LinearSVC(C=0.5, tol=0.2) 2019 capstone base' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_themes.extend(results_dict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes_results = pd.DataFrame(results_dict_themes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of results:\n",
    "## Subthemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBTHEMES RESULTS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.798670</td>\n",
       "      <td>0.328065</td>\n",
       "      <td>0.403465</td>\n",
       "      <td>0.709312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.043562</td>\n",
       "      <td>0.034901</td>\n",
       "      <td>0.933775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.448921</td>\n",
       "      <td>0.024672</td>\n",
       "      <td>0.291584</td>\n",
       "      <td>0.074228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.996627</td>\n",
       "      <td>0.190825</td>\n",
       "      <td>0.194802</td>\n",
       "      <td>0.861993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.997976</td>\n",
       "      <td>0.226291</td>\n",
       "      <td>0.437376</td>\n",
       "      <td>0.472334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC(multi_class= \"crammer_singer\")</td>\n",
       "      <td>0.707209</td>\n",
       "      <td>0.343099</td>\n",
       "      <td>0.424010</td>\n",
       "      <td>0.655067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Train Accuracy  \\\n",
       "0                                 LinearSVC        0.798670   \n",
       "1                             MultinomialNB        0.051850   \n",
       "2                                GaussianNB        0.448921   \n",
       "3                              RandomForest        0.996627   \n",
       "4                              DecisionTree        0.997976   \n",
       "5  LinearSVC(multi_class= \"crammer_singer\")        0.707209   \n",
       "\n",
       "   Validation Accuracy  Recall Score  Precision Score  \n",
       "0             0.328065      0.403465         0.709312  \n",
       "1             0.043562      0.034901         0.933775  \n",
       "2             0.024672      0.291584         0.074228  \n",
       "3             0.190825      0.194802         0.861993  \n",
       "4             0.226291      0.437376         0.472334  \n",
       "5             0.343099      0.424010         0.655067  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SUBTHEMES RESULTS \n",
    "print(\"SUBTHEMES RESULTS:\")\n",
    "my_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LinearSVC() worked the best with their default C regularization parameter. \n",
    "\n",
    "    * train score: 0.798\n",
    "    * validation score: 0.328\n",
    "    * recall score: 0.403\n",
    "    * precision score: 0.709"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THEMES RESULTS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.816596</td>\n",
       "      <td>0.484194</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.759259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.246338</td>\n",
       "      <td>0.205860</td>\n",
       "      <td>0.175235</td>\n",
       "      <td>0.949102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.363724</td>\n",
       "      <td>0.049730</td>\n",
       "      <td>0.588447</td>\n",
       "      <td>0.143599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.998554</td>\n",
       "      <td>0.427525</td>\n",
       "      <td>0.466556</td>\n",
       "      <td>0.857724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.998554</td>\n",
       "      <td>0.371241</td>\n",
       "      <td>0.604478</td>\n",
       "      <td>0.606826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC(multi_class= \"crammer_singer\")</td>\n",
       "      <td>0.757806</td>\n",
       "      <td>0.492290</td>\n",
       "      <td>0.624378</td>\n",
       "      <td>0.716688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC(C=0.5, tol=0.2) 2019 capstone base</td>\n",
       "      <td>0.710678</td>\n",
       "      <td>0.488820</td>\n",
       "      <td>0.594804</td>\n",
       "      <td>0.787701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model  Train Accuracy  \\\n",
       "0                                     LinearSVC        0.816596   \n",
       "1                                 MultinomialNB        0.246338   \n",
       "2                                    GaussianNB        0.363724   \n",
       "3                                  RandomForest        0.998554   \n",
       "4                                  DecisionTree        0.998554   \n",
       "5      LinearSVC(multi_class= \"crammer_singer\")        0.757806   \n",
       "6  LinearSVC(C=0.5, tol=0.2) 2019 capstone base        0.710678   \n",
       "\n",
       "   Validation Accuracy  Recall Score  Precision Score  \n",
       "0             0.484194      0.611940         0.759259  \n",
       "1             0.205860      0.175235         0.949102  \n",
       "2             0.049730      0.588447         0.143599  \n",
       "3             0.427525      0.466556         0.857724  \n",
       "4             0.371241      0.604478         0.606826  \n",
       "5             0.492290      0.624378         0.716688  \n",
       "6             0.488820      0.594804         0.787701  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#THEMES RESULTS \n",
    "print(\"THEMES RESULTS:\")\n",
    "\n",
    "themes_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LAST YEARS RESULTS: Results from 2019 Capstone results on test data for baseline model (BoW CountVectorizer and BinaryRelevance(LinearSVC(C=0.5, tol=0.2))\n",
    "\n",
    "     * Accuracy: 45%\n",
    "     * Recall: 0.64\n",
    "     * Precision: 0.74\n",
    "  \n",
    "> OUR RESULTS: Using LinearSVC(C=0.5, tol=0.2) 2019 capstone base, overfitting went down and only recall decreased in score. Our best results for baseline model is:\n",
    "\n",
    "     * Accuracy: 49%\n",
    "     * Recall: 0.60\n",
    "     * Precision: 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "***Previous work:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CountVecorizer for comparison vs TFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer Vectorizer Representation\n",
    "\n",
    "def count_vectorizer(train, valid):\n",
    "    cv = CountVectorizer() \n",
    "    X = cv.fit_transform(train)\n",
    "    X_valid = cv.transform(valid)\n",
    "    return X, X_valid\n",
    "\n",
    "#bow = pd.DataFrame(X_train_tfid, columns=sorted(tfid.vocabulary_), index=final_comments)\n",
    "#X_valid_tfid = tfid.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize X_train and convert Y_train to an array\n",
    "\n",
    "cvX_train, cvX_valid = count_vectorizer(X_train_Q1['clean_text'].values.astype('U'), \n",
    "                                    X_valid_Q1['clean_text'].values.astype('U')) #had to convert type \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer- FOR THEMES ONLY using LinearSVC():\n",
      "\n",
      "Training Score for Classifer Chain: 0.9588473400154202\n",
      "Validation Score for Classifer Chain: 0.41518889745566695\n",
      "Validation Recall: 0.6337755666113875\n",
      "Validation Precision: 0.6297720406481736\n"
     ]
    }
   ],
   "source": [
    "print(\"CountVectorizer- FOR THEMES ONLY using LinearSVC():\\n\")\n",
    "Classifier_Chain(cvX_train, themes_ytrain, cvX_valid, themes_yvalid, LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer-FOR SUBTHEMES ONLY using LinearSVC():\n",
      "\n",
      "Training Score for Classifer Chain: 0.968195836545875\n",
      "Validation Score for Classifer Chain: 0.27833461835003853\n",
      "Validation Recall: 0.4777227722772277\n",
      "Validation Precision: 0.5130249867091973\n"
     ]
    }
   ],
   "source": [
    "print(\"CountVectorizer-FOR SUBTHEMES ONLY using LinearSVC():\\n\")\n",
    "Classifier_Chain(cvX_train, subthemes_ytrain, cvX_valid, subthemes_yvalid, LinearSVC())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer- FOR THEMES ONLY using Decision Tree():\n",
      "\n",
      "Training Score for Classifer Chain: 0.9985543562066307\n",
      "Validation Score for Classifer Chain: 0.39321511179645335\n",
      "Validation Recall: 0.6252072968490879\n",
      "Validation Precision: 0.5751334858886347\n"
     ]
    }
   ],
   "source": [
    "print(\"CountVectorizer- FOR THEMES ONLY using Decision Tree():\\n\")\n",
    "\n",
    "Classifier_Chain(cvX_train, themes_ytrain, cvX_valid, themes_yvalid, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer- FOR SUBTHEMES ONLY using Decision Tree:\n",
      "\n",
      "Training Score for Classifer Chain: 0.9979760986892829\n",
      "Validation Score for Classifer Chain: 0.2243639167309175\n",
      "Validation Recall: 0.45024752475247526\n",
      "Validation Precision: 0.44376677238350815\n"
     ]
    }
   ],
   "source": [
    "print(\"CountVectorizer- FOR SUBTHEMES ONLY using Decision Tree:\\n\")\n",
    "\n",
    "Classifier_Chain(cvX_train, subthemes_ytrain, cvX_valid, subthemes_yvalid, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***For all themes and subthemes:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     loss='squared_hinge', max_iter=1000,\n",
       "                                     multi_class='ovr', penalty='l2',\n",
       "                                     random_state=None, tol=0.0001, verbose=0),\n",
       "                order=None, require_dense=[True, True])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LinearSVC multi_class= \"ovr\"\n",
    "#Multiclass as One-Vs-The-Rest:\n",
    "\n",
    "classifier_svc = ClassifierChain(\n",
    "    classifier = LinearSVC(multi_class= \"ovr\")\n",
    ")\n",
    "classifier_svc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score for LinearSVC Classifer Chain: 0.7907671549730146\n",
      "Validation Score for LinearSVC Classifer Chain: 0.3338473400154202\n",
      "Validation Recall for LinearSVC Classifer Chain: 0.5321232697832332\n",
      "Validation Precision for LinearSVC Classifer Chain: 0.6822367319604888\n"
     ]
    }
   ],
   "source": [
    "#Train score\n",
    "print(\"Training Score for LinearSVC Classifer Chain:\", \n",
    "      classifier_svc.score(X_train, Y_train))\n",
    "print(\"Validation Score for LinearSVC Classifer Chain:\",\n",
    "     classifier_svc.score(X_valid, np.array(y_valid_Q1)))\n",
    "\n",
    "y_pred = classifier_svc.predict(X_valid)\n",
    "print(\"Validation Recall for LinearSVC Classifer Chain:\",\n",
    "      recall_score(np.array(y_valid_Q1), y_pred, average= 'micro'))\n",
    "print(\"Validation Precision for LinearSVC Classifer Chain:\",\n",
    "     precision_score(np.array(y_valid_Q1), y_pred, average= 'micro'))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8729869538341413"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall score for training \n",
    "\n",
    "y_pred = classifier_svc.predict(X_train)\n",
    "recall_score(Y_train, y_pred, average= 'micro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
