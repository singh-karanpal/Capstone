{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model for Question 1 (data from 2013, 2018, 2020)\n",
    "## Multi-Label Classification using Classifier Chains model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is after importing preprocessing comments**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This code is from preprocessing to be used before \n",
    "#### running code below to create clean texts for fitting \n",
    "#----------------------------------------------------------------\n",
    "\n",
    "# #Create class object\n",
    "# c_pp = comment_preprocessor()\n",
    "\n",
    "# #clean X training set\n",
    "# clean_doc_train, vocab_train = c_pp.preprocess_text(list(X_train_Q1['Comment']))\n",
    "# #clean X valid\n",
    "# clean_doc_valid, vocab_valid = c_pp.preprocess_text(list(X_valid_Q1['Comment']))\n",
    "\n",
    "# ## For baseline, convert list of lists into list of sentences using the following code\n",
    "\n",
    "# clean_text = []\n",
    "# for docs in clean_doc_train:\n",
    "#     clean_text.append(' '.join(docs)) \n",
    "\n",
    "# #save clean text \n",
    "# X_train_Q1['clean_text'] = clean_text\n",
    "# X_train_Q1.to_csv('data/X_train_Q1_clean.csv', index=False)\n",
    "\n",
    "# #validation set preprocess\n",
    "# clean_text_val = []\n",
    "# for docs in clean_doc_valid:\n",
    "#     clean_text_val.append(' '.join(docs))\n",
    "\n",
    "# #save valid clean text \n",
    "# X_valid_Q1['clean_text'] = clean_text_val\n",
    "# X_valid_Q1.to_csv('data/X_valid_Q1_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in preprocessed train and validation datas\n",
    "#your path here\n",
    "\n",
    "X_train_Q1 = pd.read_csv('data/X_train_pp.csv')\n",
    "X_valid_Q1 = pd.read_csv('data/X_valid_pp.csv')\n",
    "\n",
    "y_train_Q1 = pd.read_csv('data/y_train_Q1.csv')\n",
    "y_valid_Q1 = pd.read_csv('data/y_valid_Q1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfid Vectorizer Representation\n",
    "First we'll use Tfid as vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfid Vectorizer Representation\n",
    "\n",
    "def tfid_vectorizer(train, valid):\n",
    "    \"\"\"\n",
    "    Fits the TfidVectorizer() on your X training \n",
    "    set and transform on X validation set\n",
    "    Returns the matrixes.\n",
    "    \"\"\"\n",
    "    tfid = TfidfVectorizer() \n",
    "    X = tfid.fit_transform(train)\n",
    "    X_valid = tfid.transform(valid)\n",
    "    return X, X_valid\n",
    "\n",
    "\n",
    "#To view the representation\n",
    "#bow = pd.DataFrame(X_train_tfid, columns=sorted(tfid.vocabulary_), index=final_comments)\n",
    "#bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize X_train and convert Y_train to an array\n",
    "\n",
    "X_train, X_valid = tfid_vectorizer(X_train_Q1['Comment'].values.astype('U'), \n",
    "                                    X_valid_Q1['Comment'].values.astype('U')) #had to convert type \n",
    "#ytrain for all themes and subthemes\n",
    "Y_train = (np.array(y_train_Q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme columns: 13\n",
      "Subtheme columns: 62\n"
     ]
    }
   ],
   "source": [
    "#slice y to themes and subthemes\n",
    "#y_train\n",
    "subthemes_ytrain = y_train_Q1.loc[:, 'CPD_Improve_new_employee_orientation':'OTH_Covid']\n",
    "themes_ytrain = y_train_Q1[['CPD','CB', 'EWC', 'Exec', 'FEW', 'SP', 'RE', 'Sup', 'SW', 'TEPE',\n",
    "                            'VMG', 'OTH', 'Unrelated']]\n",
    "\n",
    "#y_valid\n",
    "subthemes_yvalid = y_valid_Q1.loc[:, 'CPD_Improve_new_employee_orientation':'OTH_Covid']\n",
    "themes_yvalid = y_valid_Q1[['CPD','CB', 'EWC', 'Exec', 'FEW', 'SP', 'RE', 'Sup', \n",
    "                                      'SW', 'TEPE','VMG', 'OTH', 'Unrelated']]\n",
    "\n",
    "#shape check: 13 themes and 62 subthemes\n",
    "print('Theme columns:',themes_ytrain.shape[1])\n",
    "print('Subtheme columns:', subthemes_ytrain.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2594, 62)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(subthemes_yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2594, 13)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(themes_yvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Chain\n",
    "## Subthemes only\n",
    "### trying different models to choose best baseline classifier\n",
    "\n",
    "**Starting with Subthemes Y only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parts of code adapated from DSCI 573 lab 4\n",
    "#Dictionary of Base Models\n",
    "\n",
    "models = {\n",
    "    'LinearSVC': LinearSVC(),\n",
    "    'MultinomialNB' : MultinomialNB(),\n",
    "    'GaussianNB' : GaussianNB()#,\n",
    "    #'Random Forest' : RandomForestClassifier(), too slow will use function \n",
    "    #'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    #'Neural Net' : MLPClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For subthemes only\n",
    "#Note takes about 15 min to run\n",
    "\n",
    "results_dict = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    classifier_chain = ClassifierChain(model)\n",
    "    model = classifier_chain.fit(X_train, subthemes_ytrain)\n",
    "    train = model.score(X_train, np.array(subthemes_ytrain))\n",
    "    valid = model.score(X_valid, np.array(subthemes_yvalid))\n",
    "    y_pred = model.predict(X_valid)\n",
    "    recall = recall_score(np.array(subthemes_yvalid), y_pred, average= 'micro')\n",
    "    precision = precision_score(np.array(subthemes_yvalid), y_pred, average= 'micro')\n",
    "    \n",
    "    case= {'Model': model_name,\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}\n",
    "    \n",
    "    results_dict.append(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.770625</td>\n",
       "      <td>0.319584</td>\n",
       "      <td>0.399010</td>\n",
       "      <td>0.707638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.052525</td>\n",
       "      <td>0.042020</td>\n",
       "      <td>0.034653</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.423188</td>\n",
       "      <td>0.026214</td>\n",
       "      <td>0.314356</td>\n",
       "      <td>0.074143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Train Accuracy  Validation Accuracy  Recall Score  \\\n",
       "0      LinearSVC        0.770625             0.319584      0.399010   \n",
       "1  MultinomialNB        0.052525             0.042020      0.034653   \n",
       "2     GaussianNB        0.423188             0.026214      0.314356   \n",
       "\n",
       "   Precision Score  \n",
       "0         0.707638  \n",
       "1         0.952381  \n",
       "2         0.074143  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inital look at df\n",
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list-dictionary of basemodels\n",
    "results_dict2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier_Chain(Ytrain, Yvalid, base_model):\n",
    "    \"\"\"\n",
    "    Fits a Classifier Chain Model with the base classifier of choice and \n",
    "    using either themes or subthemes Y.\n",
    "    Show results of training accuracy score, validation accuracy score, \n",
    "    validation recall and precision scores.\n",
    "    \"\"\"\n",
    "    classifier_chain = ClassifierChain(base_model)\n",
    "    \n",
    "    model = classifier_chain.fit(X_train, subthemes_ytrain)\n",
    "    train = model.score(X_train, np.array(subthemes_ytrain))\n",
    "    valid = model.score(X_valid, np.array(subthemes_yvalid))\n",
    "    y_pred = model.predict(X_valid)\n",
    "    recall = recall_score(np.array(subthemes_yvalid), y_pred, average= 'micro')\n",
    "    precision = precision_score(np.array(subthemes_yvalid), y_pred, average= 'micro')\n",
    "    \n",
    "    case= {'Model': base_model,\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}\n",
    "    \n",
    "    results_dict2.append(case)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Model': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=None, oob_score=False, random_state=None,\n",
       "                         verbose=0, warm_start=False),\n",
       "  'Train Accuracy': 0.9973978411719352,\n",
       "  'Validation Accuracy': 0.19236700077101002,\n",
       "  'Recall Score': 0.19876237623762377,\n",
       "  'Precision Score': 0.8606645230439443}]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest' : RandomForestClassifier()\n",
    "#Note takes quite some time ~15 min on my computer\n",
    "Classifier_Chain(subthemes_ytrain, subthemes_yvalid, RandomForestClassifier())\n",
    "results_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict2[0]['Model'] = 'RandomForest' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Model': 'RandomForest',\n",
       "  'Train Accuracy': 0.9973978411719352,\n",
       "  'Validation Accuracy': 0.19236700077101002,\n",
       "  'Recall Score': 0.19876237623762377,\n",
       "  'Precision Score': 0.8606645230439443},\n",
       " {'Model': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                         max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                         random_state=None, splitter='best'),\n",
       "  'Train Accuracy': 0.9982652274479569,\n",
       "  'Validation Accuracy': 0.21703932151117963,\n",
       "  'Recall Score': 0.43143564356435643,\n",
       "  'Precision Score': 0.4634405743153417}]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree' : DecisionTreeClassifier()\n",
    "#Note takes quite some time ~15 min on my computer\n",
    "Classifier_Chain(subthemes_ytrain, subthemes_yvalid, DecisionTreeClassifier())\n",
    "results_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict2[1]['Model'] = 'DecisionTree' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC(multi_class= \"crammer_singer\")\n",
    "#\"crammer_singer\" optimizes a joint objective over all classes.\n",
    "Classifier_Chain(subthemes_ytrain, subthemes_yvalid, LinearSVC(multi_class= \"crammer_singer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict2[2]['Model'] = 'LinearSVC(multi_class= \"crammer_singer\")' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying last year's base classifier LinearSVC(C=0.5, tol=0.2)\n",
    "\n",
    "#results_dict2 = []\n",
    "Classifier_Chain(subthemes_ytrain, subthemes_yvalid, LinearSVC(C=0.5, tol=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict2[3]['Model'] = 'LinearSVC(C=0.5, tol=0.2) 2019 capstone base' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict.extend(results_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.770625</td>\n",
       "      <td>0.319584</td>\n",
       "      <td>0.399010</td>\n",
       "      <td>0.707638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.052525</td>\n",
       "      <td>0.042020</td>\n",
       "      <td>0.034653</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.423188</td>\n",
       "      <td>0.026214</td>\n",
       "      <td>0.314356</td>\n",
       "      <td>0.074143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.997398</td>\n",
       "      <td>0.192367</td>\n",
       "      <td>0.198762</td>\n",
       "      <td>0.860665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.998265</td>\n",
       "      <td>0.217039</td>\n",
       "      <td>0.431436</td>\n",
       "      <td>0.463441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC(multi_class= \"crammer_singer\")</td>\n",
       "      <td>0.681766</td>\n",
       "      <td>0.338088</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.654594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC(C=0.5, tol=0.2) 2019 capstone base</td>\n",
       "      <td>0.543562</td>\n",
       "      <td>0.312645</td>\n",
       "      <td>0.373762</td>\n",
       "      <td>0.754246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model  Train Accuracy  \\\n",
       "0                                     LinearSVC        0.770625   \n",
       "1                                 MultinomialNB        0.052525   \n",
       "2                                    GaussianNB        0.423188   \n",
       "3                                  RandomForest        0.997398   \n",
       "4                                  DecisionTree        0.998265   \n",
       "5      LinearSVC(multi_class= \"crammer_singer\")        0.681766   \n",
       "6  LinearSVC(C=0.5, tol=0.2) 2019 capstone base        0.543562   \n",
       "\n",
       "   Validation Accuracy  Recall Score  Precision Score  \n",
       "0             0.319584      0.399010         0.707638  \n",
       "1             0.042020      0.034653         0.952381  \n",
       "2             0.026214      0.314356         0.074143  \n",
       "3             0.192367      0.198762         0.860665  \n",
       "4             0.217039      0.431436         0.463441  \n",
       "5             0.338088      0.425000         0.654594  \n",
       "6             0.312645      0.373762         0.754246  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_results =pd.DataFrame(results_dict)\n",
    "my_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***All models overfitting especially the Tree models. Best one overall is LinearSVC with default multi-class='ovr'. Still overfitting though, try tune regularization (less regularization is larger C)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping through various C value in LinearSVC\n",
    "\n",
    "scores = []\n",
    "for i in (10.0**np.arange(-4,4)):\n",
    "    model = ClassifierChain(LinearSVC(C = i, max_iter = 100000)).fit(X_train, subthemes_ytrain)\n",
    "    #train = model.score(X_train, np.array(subthemes_ytrain))\n",
    "    valid = model.score(X_valid, np.array(subthemes_yvalid))\n",
    "    \n",
    "    scores.append(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10.0**np.arange(-4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0007710100231303007,\n",
       " 0.0007710100231303007,\n",
       " 0.05127216653816499,\n",
       " 0.24518118735543562,\n",
       " 0.31958365458750965,\n",
       " 0.2779491133384734,\n",
       " 0.24518118735543562,\n",
       " 0.23014649190439476]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Regularization doesn't help here. The best validation score is given by the default C hyperparameter = 1.0. Let's try this on LinearSVC(multi-class='crammer_singer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping through various C value in LinearSVC multiclass= crammer_singer \n",
    "\n",
    "scores = []\n",
    "for i in (10.0**np.arange(-4,4)):\n",
    "    model = ClassifierChain(LinearSVC(multi_class= \"crammer_singer\", C = i, max_iter = 100000)).fit(X_train, subthemes_ytrain)\n",
    "    #train = model.score(X_train, np.array(subthemes_ytrain))\n",
    "    valid = model.score(X_valid, np.array(subthemes_yvalid))\n",
    "    \n",
    "    scores.append(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0007710100231303007,\n",
       " 0.0007710100231303007,\n",
       " 0.009252120277563608,\n",
       " 0.19275250578257516,\n",
       " 0.3430994602929838,\n",
       " 0.2679259830377795,\n",
       " 0.25212027756360833,\n",
       " 0.24710871241326138]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Same results for C values of crammer_singer. Seems that Linear(SVC) with its default regularization gives the highest\n",
    "\n",
    "> Due to lack of resources could not find proper way to GridSeach with multilabel classifier. https://stackoverflow.com/questions/26018543/gridsearch-for-multi-label-classification-in-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearSVC': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "           intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "           multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "           verbose=0),\n",
       " 'MultinomialNB': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " 'GaussianNB': GaussianNB(priors=None, var_smoothing=1e-09)}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For themes Y \n",
    "\n",
    "## working the same steps on Themes to find base classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For themes only\n",
    "#Note takes about ~15 min to run\n",
    "results_dict_themes = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    classifier_chain = ClassifierChain(model)\n",
    "    model = classifier_chain.fit(X_train, themes_ytrain)\n",
    "    train = model.score(X_train, np.array(themes_ytrain))\n",
    "    valid = model.score(X_valid, np.array(themes_yvalid))\n",
    "    y_pred = model.predict(X_valid)\n",
    "    recall = recall_score(np.array(themes_yvalid), y_pred, average= 'micro')\n",
    "    precision = precision_score(np.array(themes_yvalid), y_pred, average= 'micro')\n",
    "    \n",
    "    case= {'Model': model_name,\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}\n",
    "    \n",
    "    results_dict_themes.append(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.791345</td>\n",
       "      <td>0.476099</td>\n",
       "      <td>0.608347</td>\n",
       "      <td>0.749915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.246338</td>\n",
       "      <td>0.212028</td>\n",
       "      <td>0.181039</td>\n",
       "      <td>0.942446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.336546</td>\n",
       "      <td>0.047417</td>\n",
       "      <td>0.622996</td>\n",
       "      <td>0.144090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Train Accuracy  Validation Accuracy  Recall Score  \\\n",
       "0      LinearSVC        0.791345             0.476099      0.608347   \n",
       "1  MultinomialNB        0.246338             0.212028      0.181039   \n",
       "2     GaussianNB        0.336546             0.047417      0.622996   \n",
       "\n",
       "   Precision Score  \n",
       "0         0.749915  \n",
       "1         0.942446  \n",
       "2         0.144090  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict_themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty out list\n",
    "results_dict3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier_Chain(Ytrain, Yvalid, base_model):\n",
    "    \"\"\"\n",
    "    Fits a Classifier Chain Model with the base classifier of choice and \n",
    "    using either themes or subthemes Y.\n",
    "    Show results of training accuracy score, validation accuracy score, \n",
    "    validation recall and precision scores.\n",
    "    \"\"\"\n",
    "    classifier_chain = ClassifierChain(base_model)\n",
    "    \n",
    "    model = classifier_chain.fit(X_train, themes_ytrain) #subthemes_ytrain)\n",
    "    train = model.score(X_train, np.array(themes_ytrain)) #subthemes_ytrain\n",
    "    valid = model.score(X_valid, np.array(themes_yvalid)) #subthemes_yvalid\n",
    "    y_pred = model.predict(X_valid)\n",
    "    recall = recall_score(np.array(themes_yvalid), y_pred, average= 'micro') #subthemes_yvalid\n",
    "    precision = precision_score(np.array(themes_yvalid), y_pred, average= 'micro') #subthemes_yvalid\n",
    "    \n",
    "    case= {'Model': base_model,\n",
    "           'Train Accuracy': train,\n",
    "           'Validation Accuracy': valid,\n",
    "           'Recall Score': recall,\n",
    "           'Precision Score': precision}\n",
    "    \n",
    "    #print(case)\n",
    "    results_dict3.append(case)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest' : RandomForestClassifier()\n",
    "#Note takes quite some time ~15 min on my computer\n",
    "Classifier_Chain(themes_ytrain, themes_yvalid, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict3[0]['Model'] = 'RandomForest' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree' : DecisionTreeClassifier()\n",
    "#Note takes quite some time ~15 min on my computer\n",
    "Classifier_Chain(themes_ytrain, themes_yvalid, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict3[1]['Model'] = 'DecisionTree' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC(multi_class= \"crammer_singer\")\n",
    "#\"crammer_singer\" optimizes a joint objective over all classes.\n",
    "Classifier_Chain(themes_ytrain, themes_yvalid, LinearSVC(multi_class= \"crammer_singer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict3[2]['Model'] = 'LinearSVC(multi_class= \"crammer_singer\")' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_themes.extend(results_dict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.791345</td>\n",
       "      <td>0.476099</td>\n",
       "      <td>0.608347</td>\n",
       "      <td>0.749915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.246338</td>\n",
       "      <td>0.212028</td>\n",
       "      <td>0.181039</td>\n",
       "      <td>0.942446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.336546</td>\n",
       "      <td>0.047417</td>\n",
       "      <td>0.622996</td>\n",
       "      <td>0.144090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.998458</td>\n",
       "      <td>0.417116</td>\n",
       "      <td>0.453566</td>\n",
       "      <td>0.857367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.998651</td>\n",
       "      <td>0.350810</td>\n",
       "      <td>0.588170</td>\n",
       "      <td>0.590128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC(multi_class= \"crammer_singer\")</td>\n",
       "      <td>0.736507</td>\n",
       "      <td>0.499229</td>\n",
       "      <td>0.628524</td>\n",
       "      <td>0.720989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Train Accuracy  \\\n",
       "0                                 LinearSVC        0.791345   \n",
       "1                             MultinomialNB        0.246338   \n",
       "2                                GaussianNB        0.336546   \n",
       "3                              RandomForest        0.998458   \n",
       "4                              DecisionTree        0.998651   \n",
       "5  LinearSVC(multi_class= \"crammer_singer\")        0.736507   \n",
       "\n",
       "   Validation Accuracy  Recall Score  Precision Score  \n",
       "0             0.476099      0.608347         0.749915  \n",
       "1             0.212028      0.181039         0.942446  \n",
       "2             0.047417      0.622996         0.144090  \n",
       "3             0.417116      0.453566         0.857367  \n",
       "4             0.350810      0.588170         0.590128  \n",
       "5             0.499229      0.628524         0.720989  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict_themes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For themes, also looks like LinearSVC() is the best. Hypothesizing that the best regularization parameter C for this model is their default values. Let's see if regularizing Decision Tree will help with overfitting and get better validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping through various max_depth value in LinearSVC multiclass= crammer_singer \n",
    "\n",
    "scores = []\n",
    "for i in range(10,100,10):\n",
    "    model = ClassifierChain(DecisionTreeClassifier(max_depth = i)).fit(X_train, themes_ytrain)\n",
    "    #train = model.score(X_train, np.array(subthemes_ytrain))\n",
    "    valid = model.score(X_valid, np.array(themes_yvalid))\n",
    "    \n",
    "    scores.append(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3797224363916731,\n",
       " 0.4055512721665382,\n",
       " 0.4109483423284503,\n",
       " 0.40670778720123363,\n",
       " 0.3982266769468003,\n",
       " 0.40400925212027755,\n",
       " 0.39552814186584423,\n",
       " 0.39167309175019277,\n",
       " 0.38781804163454126]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Looks like none of these max depths improves the validation accuracy with None of result 0.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset list\n",
    "results_dict3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying last year's base classifier LinearSVC(C=0.5, tol=0.2)\n",
    "Classifier_Chain(themes_ytrain, themes_yvalid, LinearSVC(C=0.5, tol=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict3[0]['Model'] = 'LinearSVC(C=0.5, tol=0.2) 2019 capstone base' #rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_themes.extend(results_dict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes_results = pd.DataFrame(results_dict_themes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of results:\n",
    "## Subthemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBTHEMES RESULTS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.770625</td>\n",
       "      <td>0.319584</td>\n",
       "      <td>0.399010</td>\n",
       "      <td>0.707638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.052525</td>\n",
       "      <td>0.042020</td>\n",
       "      <td>0.034653</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.423188</td>\n",
       "      <td>0.026214</td>\n",
       "      <td>0.314356</td>\n",
       "      <td>0.074143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.997398</td>\n",
       "      <td>0.192367</td>\n",
       "      <td>0.198762</td>\n",
       "      <td>0.860665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.998265</td>\n",
       "      <td>0.217039</td>\n",
       "      <td>0.431436</td>\n",
       "      <td>0.463441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC(multi_class= \"crammer_singer\")</td>\n",
       "      <td>0.681766</td>\n",
       "      <td>0.338088</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.654594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC(C=0.5, tol=0.2) 2019 capstone base</td>\n",
       "      <td>0.543562</td>\n",
       "      <td>0.312645</td>\n",
       "      <td>0.373762</td>\n",
       "      <td>0.754246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model  Train Accuracy  \\\n",
       "0                                     LinearSVC        0.770625   \n",
       "1                                 MultinomialNB        0.052525   \n",
       "2                                    GaussianNB        0.423188   \n",
       "3                                  RandomForest        0.997398   \n",
       "4                                  DecisionTree        0.998265   \n",
       "5      LinearSVC(multi_class= \"crammer_singer\")        0.681766   \n",
       "6  LinearSVC(C=0.5, tol=0.2) 2019 capstone base        0.543562   \n",
       "\n",
       "   Validation Accuracy  Recall Score  Precision Score  \n",
       "0             0.319584      0.399010         0.707638  \n",
       "1             0.042020      0.034653         0.952381  \n",
       "2             0.026214      0.314356         0.074143  \n",
       "3             0.192367      0.198762         0.860665  \n",
       "4             0.217039      0.431436         0.463441  \n",
       "5             0.338088      0.425000         0.654594  \n",
       "6             0.312645      0.373762         0.754246  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SUBTHEMES RESULTS \n",
    "print(\"SUBTHEMES RESULTS:\")\n",
    "my_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LinearSVC() worked the best with their default C regularization parameter. \n",
    "\n",
    "    * train score: 0.77\n",
    "    * validation score: 0.32\n",
    "    * recall score: 0.40\n",
    "    * precision score: 0.71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THEMES RESULTS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.791345</td>\n",
       "      <td>0.476099</td>\n",
       "      <td>0.608347</td>\n",
       "      <td>0.749915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.246338</td>\n",
       "      <td>0.212028</td>\n",
       "      <td>0.181039</td>\n",
       "      <td>0.942446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.336546</td>\n",
       "      <td>0.047417</td>\n",
       "      <td>0.622996</td>\n",
       "      <td>0.144090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.998458</td>\n",
       "      <td>0.417116</td>\n",
       "      <td>0.453566</td>\n",
       "      <td>0.857367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.998651</td>\n",
       "      <td>0.350810</td>\n",
       "      <td>0.588170</td>\n",
       "      <td>0.590128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC(multi_class= \"crammer_singer\")</td>\n",
       "      <td>0.736507</td>\n",
       "      <td>0.499229</td>\n",
       "      <td>0.628524</td>\n",
       "      <td>0.720989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC(C=0.5, tol=0.2) 2019 capstone base</td>\n",
       "      <td>0.692174</td>\n",
       "      <td>0.478797</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.779920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model  Train Accuracy  \\\n",
       "0                                     LinearSVC        0.791345   \n",
       "1                                 MultinomialNB        0.246338   \n",
       "2                                    GaussianNB        0.336546   \n",
       "3                                  RandomForest        0.998458   \n",
       "4                                  DecisionTree        0.998651   \n",
       "5      LinearSVC(multi_class= \"crammer_singer\")        0.736507   \n",
       "6  LinearSVC(C=0.5, tol=0.2) 2019 capstone base        0.692174   \n",
       "\n",
       "   Validation Accuracy  Recall Score  Precision Score  \n",
       "0             0.476099      0.608347         0.749915  \n",
       "1             0.212028      0.181039         0.942446  \n",
       "2             0.047417      0.622996         0.144090  \n",
       "3             0.417116      0.453566         0.857367  \n",
       "4             0.350810      0.588170         0.590128  \n",
       "5             0.499229      0.628524         0.720989  \n",
       "6             0.478797      0.592593         0.779920  "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#THEMES RESULTS \n",
    "print(\"THEMES RESULTS:\")\n",
    "\n",
    "themes_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LAST YEARS RESULTS: Results from 2019 Capstone results on test data for baseline model (BoW CountVectorizer and BinaryRelevance(LinearSVC(C=0.5, tol=0.2))\n",
    "\n",
    "     * Accuracy: 45%\n",
    "     * Recall: 0.64\n",
    "     * Precision: 0.74\n",
    "  \n",
    "> OUR RESULTS: Using LinearSVC(C=0.5, tol=0.2) 2019 capstone base, overfitting went down and only recall decreased in score. Our best results for baseline model is:\n",
    "\n",
    "     * Accuracy: 48%\n",
    "     * Recall: 0.59\n",
    "     * Precision: 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using universal sentence encoder as embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = pd.read_csv('data/X_train_Q1_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), \n",
    "                 tf.tables_initializer()])\n",
    "    training_embeddings = session.run(embed(X_train_raw.Comment.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "use = ClassifierChain(LinearSVC(C=0.5, tol=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=LinearSVC(C=0.5, class_weight=None, dual=True,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     loss='squared_hinge', max_iter=1000,\n",
       "                                     multi_class='ovr', penalty='l2',\n",
       "                                     random_state=None, tol=0.2, verbose=0),\n",
       "                order=None, require_dense=[True, True])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use.fit(training_embeddings, themes_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4995181187355436"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use.score(training_embeddings, themes_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming valiation set\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), \n",
    "                 tf.tables_initializer()])\n",
    "    test_embeddings = session.run(embed(X_valid_Q1.Comment.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44680030840400925"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use.score(test_embeddings, themes_yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = use.predict(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5702045328911001"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(np.array(themes_yvalid), y_pred, average= 'micro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7094222833562586"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(np.array(themes_yvalid), y_pred, average= 'micro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_sent = []\n",
    "case= {'Model': 'Universal Sentence Encoder LinearSVC',\n",
    "       'Train Accuracy': use.score(training_embeddings, themes_ytrain),\n",
    "       'Validation Accuracy': use.score(test_embeddings, themes_yvalid),\n",
    "       'Recall Score': recall_score(np.array(themes_yvalid), y_pred, average= 'micro') ,\n",
    "       'Precision Score': precision_score(np.array(themes_yvalid), y_pred, average= 'micro') }\n",
    "\n",
    "#print(case)\n",
    "uni_sent.append(case)    \n",
    "results_dict_themes.extend(uni_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.791345</td>\n",
       "      <td>0.476099</td>\n",
       "      <td>0.608347</td>\n",
       "      <td>0.749915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.246338</td>\n",
       "      <td>0.212028</td>\n",
       "      <td>0.181039</td>\n",
       "      <td>0.942446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.336546</td>\n",
       "      <td>0.047417</td>\n",
       "      <td>0.622996</td>\n",
       "      <td>0.144090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.998458</td>\n",
       "      <td>0.417116</td>\n",
       "      <td>0.453566</td>\n",
       "      <td>0.857367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.998651</td>\n",
       "      <td>0.350810</td>\n",
       "      <td>0.588170</td>\n",
       "      <td>0.590128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC(multi_class= \"crammer_singer\")</td>\n",
       "      <td>0.736507</td>\n",
       "      <td>0.499229</td>\n",
       "      <td>0.628524</td>\n",
       "      <td>0.720989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC(C=0.5, tol=0.2) 2019 capstone base</td>\n",
       "      <td>0.692174</td>\n",
       "      <td>0.478797</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.779920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Universal Sentence Encoder LinearSVC</td>\n",
       "      <td>0.499518</td>\n",
       "      <td>0.446800</td>\n",
       "      <td>0.570205</td>\n",
       "      <td>0.709422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model  Train Accuracy  \\\n",
       "0                                     LinearSVC        0.791345   \n",
       "1                                 MultinomialNB        0.246338   \n",
       "2                                    GaussianNB        0.336546   \n",
       "3                                  RandomForest        0.998458   \n",
       "4                                  DecisionTree        0.998651   \n",
       "5      LinearSVC(multi_class= \"crammer_singer\")        0.736507   \n",
       "6  LinearSVC(C=0.5, tol=0.2) 2019 capstone base        0.692174   \n",
       "7          Universal Sentence Encoder LinearSVC        0.499518   \n",
       "\n",
       "   Validation Accuracy  Recall Score  Precision Score  \n",
       "0             0.476099      0.608347         0.749915  \n",
       "1             0.212028      0.181039         0.942446  \n",
       "2             0.047417      0.622996         0.144090  \n",
       "3             0.417116      0.453566         0.857367  \n",
       "4             0.350810      0.588170         0.590128  \n",
       "5             0.499229      0.628524         0.720989  \n",
       "6             0.478797      0.592593         0.779920  \n",
       "7             0.446800      0.570205         0.709422  "
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict_themes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Hierachical Multi-Classifier\n",
    "\n",
    "- trying to get hmm to work but exceptions trouble importing\n",
    "https://github.com/davidwarshaw/hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassHierarchy:\n",
    "    \"\"\"\n",
    "    Class for class heirarchy.\n",
    "    Parameters\n",
    "    ----------\n",
    "        root :\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.nodes = {}\n",
    "\n",
    "    def _get_parent(self, child):\n",
    "        # Return the parent of this node\n",
    "        return self.nodes[child] if (child in self.nodes and child != self.root) else self.root\n",
    "\n",
    "    def _get_children(self, parent):\n",
    "        # Return a list of children nodes in alpha order\n",
    "        return sorted([child for child, childs_parent in\n",
    "                       self.nodes.iteritems() if childs_parent == parent])\n",
    "\n",
    "    def _get_ancestors(self, child):\n",
    "        # Return a list of the ancestors of this node\n",
    "        # Not including root, not including the child\n",
    "        ancestors = []\n",
    "        while True:\n",
    "            child = self._get_parent(child)\n",
    "            if child == self.root:\n",
    "                break\n",
    "            ancestors.append(child)\n",
    "        return ancestors\n",
    "\n",
    "    def _get_descendants(self, parent):\n",
    "        # Return a list of the descendants of this node\n",
    "        # Not including the parent\n",
    "        descendants = []\n",
    "        self._depth_first(parent, descendants)\n",
    "        descendants.remove(parent)\n",
    "        return descendants\n",
    "\n",
    "    def _is_descendant(self, parent, child):\n",
    "        while child != self.class_hierarchy.root and child != parent:\n",
    "            child = self.class_hierarchy._get_parent(child)\n",
    "        return child == parent\n",
    "\n",
    "    def _is_ancestor(self, parent, child):\n",
    "        return _is_descendant(parent, child)\n",
    "\n",
    "    def _depth_first_print(self, parent, indent, last):\n",
    "        print(indent, end=\"\")\n",
    "        if last:\n",
    "            print(u\"\\u2514\\u2500\", end=\"\")\n",
    "            indent += \"  \"\n",
    "        else:\n",
    "            print(u\"\\u251C\\u2500\", end=\"\")\n",
    "            indent += u\"\\u2502 \"\n",
    "        print(parent)\n",
    "        num_nodes = len(self._get_children(parent))\n",
    "        node_count = 0\n",
    "        for node in self._get_children(parent):\n",
    "            node_count += 1\n",
    "            self._depth_first_print(node, indent, node_count == num_nodes)\n",
    "\n",
    "    def _depth_first(self, parent, classes):\n",
    "        classes.append(parent)\n",
    "        for node in self._get_children(parent):\n",
    "            self._depth_first(node, classes)\n",
    "\n",
    "    def add_node(self, child, parent):\n",
    "        \"\"\"\n",
    "        Add a child-parent node to the class hierarchy.\n",
    "        \"\"\"\n",
    "        if child == self.root:\n",
    "            raise ValueError('The hierarchy root: ' + child.encode('utf-8') + ' is not a valid child node.')\n",
    "        if child in self.nodes.keys():\n",
    "            if self.nodes[child] != parent:\n",
    "                raise ValueError('Node: ' + child.encode('utf-8') + ' has already been assigned parent: ' +\n",
    "                                 child.encode('utf-8'))\n",
    "            else:\n",
    "                return\n",
    "        self.nodes[child] = parent\n",
    "\n",
    "    def nodes_(self):\n",
    "        \"\"\"\n",
    "        Return the hierarchy classes as a list of child-parent nodes.\n",
    "        \"\"\"\n",
    "        return self.nodes\n",
    "\n",
    "    def classes_(self):\n",
    "        \"\"\"\n",
    "        Return the hierarchy classes as a list of unique classes.\n",
    "        \"\"\"\n",
    "        classes = []\n",
    "        self._depth_first(self.root, classes)\n",
    "        return classes\n",
    "\n",
    "    def print_(self):\n",
    "        \"\"\"\n",
    "        Pretty print the class hierarchy.\n",
    "        \"\"\"\n",
    "        self._depth_first_print(self.root, \"\", True)\n",
    "\n",
    "# =============================================================================\n",
    "# Decision Tree Hierarchical Classifier\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "class DecisionTreeHierarchicalClassifier:\n",
    "\n",
    "    def __init__(self, class_hierarchy):\n",
    "        self.stages = []\n",
    "        self.class_hierarchy = class_hierarchy\n",
    "        self._depth_first_stages(self.stages, self.class_hierarchy.root, 0)\n",
    "\n",
    "    def _depth_first_class_prob(self, tree, node, indent, last, hand):\n",
    "        if node == -1:\n",
    "            return\n",
    "        print(indent, end=\"\")\n",
    "        if last:\n",
    "            print(u\"\\u2514\\u2500\", end=\"\")\n",
    "            indent += \"    \"\n",
    "        else:\n",
    "            print(u\"\\u251C\\u2500\", end=\"\")\n",
    "            indent += u\"\\u2502   \"\n",
    "        print(hand + \" \" + node.encode('utf-8'))\n",
    "        for k, count in enumerate(tree.tree_.value[node][0]):\n",
    "            print(indent + tree.classes_[k].encode('utf-8') + \":\" +\n",
    "                  stage(count / tree.tree_.n_node_samples[node], 2).encode('utf-8'))\n",
    "        self._depth_first_class_prob(tree, tree.tree_.children_right[node], indent, False, \"R\")\n",
    "        self._depth_first_class_prob(tree, tree.tree_.children_left[node], indent, True, \"L\")\n",
    "\n",
    "    def _depth_first_stages(self, stages, parent, depth):\n",
    "        # Get the children of this parent\n",
    "        children = self.class_hierarchy._get_children(parent)\n",
    "        # If there are children, build a classification stage\n",
    "        if len(children) > 0:\n",
    "            # Assign stage props and append\n",
    "            stage = {}\n",
    "            stage['depth'] = depth\n",
    "            stage['stage'] = parent\n",
    "            stage['labels'] = children\n",
    "            stage['classes'] = stage['labels'] + [stage['stage']]\n",
    "            stage['target'] = 'target_stage_' + parent\n",
    "            stages.append(stage)\n",
    "            # Recurse through children\n",
    "            for node in children:\n",
    "                self._depth_first_stages(stages, node, depth + 1)\n",
    "\n",
    "    def _recode_label(self, classes, label):\n",
    "        # Reassign labels to their parents until either we hit the root, or an output class\n",
    "        while label != self.class_hierarchy.root and label not in classes:\n",
    "            label = self.class_hierarchy._get_parent(label)\n",
    "        return label\n",
    "\n",
    "    def _prep_data(self, X, y):\n",
    "        # Design matrix columns\n",
    "        dm_cols = range(0, X.shape[1])\n",
    "        # Target columns\n",
    "        target = X.shape[1]\n",
    "        # Dataframe\n",
    "        df = pd.concat([X, y], axis=1, ignore_index=True)\n",
    "        # Create a target column for each stage with the recoded labels\n",
    "        for stage_number, stage in enumerate(self.stages):\n",
    "            df[stage['target']] = pd.DataFrame.apply(\n",
    "                df[[target]],\n",
    "                lambda row: self._recode_label(stage['classes'], row[target]),\n",
    "                axis=1)\n",
    "        return df, dm_cols\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Build a decision tree multi-classifier from training data (X, y).\n",
    "        \"\"\"\n",
    "        # Prep data\n",
    "        df, dm_cols = self._prep_data(X, y)\n",
    "        # Fit each stage\n",
    "        for stage_number, stage in enumerate(self.stages):\n",
    "            dm = df[df[stage['target']].isin(stage['classes'])][dm_cols]\n",
    "            y_stage = df[df[stage['target']].isin(stage['classes'])][[stage['target']]]\n",
    "            stage['tree'] = tree.DecisionTreeClassifier()\n",
    "            if dm.empty:\n",
    "                warnings.warn('No samples to fit for stage ' + stage['stage'].encode('utf-8'),\n",
    "                              NoSamplesForStageWarning)\n",
    "                continue\n",
    "            stage['tree'] = stage['tree'].fit(dm, y_stage)\n",
    "        return self\n",
    "\n",
    "    def _check_fit(self):\n",
    "        for stage in self.stages:\n",
    "            if 'tree' not in stage.keys():\n",
    "                raise ClassifierNotFitError(\n",
    "                    'Estimators not fitted, call `fit` before exploiting the model.')\n",
    "\n",
    "    def _predict_stages(self, X):\n",
    "        # Score each stage\n",
    "        for stage_number, stage in enumerate(self.stages):\n",
    "            if stage_number == 0:\n",
    "                y_hat = pd.DataFrame(\n",
    "                    [self.class_hierarchy.root] * len(X),\n",
    "                    columns=[self.class_hierarchy.root],\n",
    "                    index=X.index)\n",
    "            else:\n",
    "                y_hat[stage['stage']] = y_hat[self.stages[stage_number - 1]['stage']]\n",
    "            dm = X[y_hat[stage['stage']].isin([stage['stage']])]\n",
    "            # Skip empty matrices\n",
    "            if dm.empty:\n",
    "                warnings.warn('No samples to predict for stage ' + stage['stage'].encode('utf-8'),\n",
    "                              NoSamplesForStageWarning)\n",
    "                continue\n",
    "            if not stage['tree'].tree_:\n",
    "                warnings.warn('No tree was fit for stage ' + stage['stage'].encode('utf-8'),\n",
    "                              StageNotFitWarning)\n",
    "                continue\n",
    "            # combine_first reorders DataFrames, so we have to do this the ugly way\n",
    "            y_hat_stage = pd.DataFrame(stage['tree'].predict(dm), index=dm.index)\n",
    "            y_hat = y_hat.assign(stage_col=y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[stage['stage']])\n",
    "            y_hat = y_hat.drop(stage['stage'], axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': stage['stage']})\n",
    "        # Return predicted class for each stage\n",
    "        return y_hat\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class for X.\n",
    "        \"\"\"\n",
    "        # Check that the trees have been fit\n",
    "        self._check_fit()\n",
    "        y_hat = self._predict_stages(X)\n",
    "        # Return only final predicted class\n",
    "        return y_hat.ix[:, y_hat.shape[1] - 1].as_matrix()\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Returns the mean accuracy on the given test data (X, y).\n",
    "        \"\"\"\n",
    "        # Check that the trees have been fit\n",
    "        self._check_fit()\n",
    "        y_pred = pd.DataFrame(self.predict(X), columns=['y_hat'], index=y.index)\n",
    "        return metrics.accuracy_score(self.class_hierarchy, y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-267-ef01f8fe9798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdt_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdt_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train, y_train)\n",
    "dt_predicted = dt.predict(X_test)\n",
    "dt_accuracy = dt.score(X_test, y_test)\n",
    "\n",
    "dth = hmc.DecisionTreeHierarchicalClassifier(ch)\n",
    "dth = dth.fit(X_train, y_train)\n",
    "dth_predicted = dth.predict(X_test)\n",
    "dth_accuracy = dth.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "***Previous work:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CountVecorizer for comparison vs TFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer Vectorizer Representation\n",
    "\n",
    "def count_vectorizer(train, valid):\n",
    "    cv = CountVectorizer() \n",
    "    X = cv.fit_transform(train)\n",
    "    X_valid = cv.transform(valid)\n",
    "    return X, X_valid\n",
    "\n",
    "#bow = pd.DataFrame(X_train_tfid, columns=sorted(tfid.vocabulary_), index=final_comments)\n",
    "#X_valid_tfid = tfid.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize X_train and convert Y_train to an array\n",
    "\n",
    "cvX_train, cvX_valid = count_vectorizer(X_train_Q1['clean_text'].values.astype('U'), \n",
    "                                    X_valid_Q1['clean_text'].values.astype('U')) #had to convert type \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer- FOR THEMES ONLY using LinearSVC():\n",
      "\n",
      "Training Score for Classifer Chain: 0.9588473400154202\n",
      "Validation Score for Classifer Chain: 0.41518889745566695\n",
      "Validation Recall: 0.6337755666113875\n",
      "Validation Precision: 0.6297720406481736\n"
     ]
    }
   ],
   "source": [
    "print(\"CountVectorizer- FOR THEMES ONLY using LinearSVC():\\n\")\n",
    "Classifier_Chain(cvX_train, themes_ytrain, cvX_valid, themes_yvalid, LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer-FOR SUBTHEMES ONLY using LinearSVC():\n",
      "\n",
      "Training Score for Classifer Chain: 0.968195836545875\n",
      "Validation Score for Classifer Chain: 0.27833461835003853\n",
      "Validation Recall: 0.4777227722772277\n",
      "Validation Precision: 0.5130249867091973\n"
     ]
    }
   ],
   "source": [
    "print(\"CountVectorizer-FOR SUBTHEMES ONLY using LinearSVC():\\n\")\n",
    "Classifier_Chain(cvX_train, subthemes_ytrain, cvX_valid, subthemes_yvalid, LinearSVC())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer- FOR THEMES ONLY using Decision Tree():\n",
      "\n",
      "Training Score for Classifer Chain: 0.9985543562066307\n",
      "Validation Score for Classifer Chain: 0.39321511179645335\n",
      "Validation Recall: 0.6252072968490879\n",
      "Validation Precision: 0.5751334858886347\n"
     ]
    }
   ],
   "source": [
    "print(\"CountVectorizer- FOR THEMES ONLY using Decision Tree():\\n\")\n",
    "\n",
    "Classifier_Chain(cvX_train, themes_ytrain, cvX_valid, themes_yvalid, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer- FOR SUBTHEMES ONLY using Decision Tree:\n",
      "\n",
      "Training Score for Classifer Chain: 0.9979760986892829\n",
      "Validation Score for Classifer Chain: 0.2243639167309175\n",
      "Validation Recall: 0.45024752475247526\n",
      "Validation Precision: 0.44376677238350815\n"
     ]
    }
   ],
   "source": [
    "print(\"CountVectorizer- FOR SUBTHEMES ONLY using Decision Tree:\\n\")\n",
    "\n",
    "Classifier_Chain(cvX_train, subthemes_ytrain, cvX_valid, subthemes_yvalid, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***For all themes and subthemes:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     loss='squared_hinge', max_iter=1000,\n",
       "                                     multi_class='ovr', penalty='l2',\n",
       "                                     random_state=None, tol=0.0001, verbose=0),\n",
       "                order=None, require_dense=[True, True])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LinearSVC multi_class= \"ovr\"\n",
    "#Multiclass as One-Vs-The-Rest:\n",
    "\n",
    "classifier_svc = ClassifierChain(\n",
    "    classifier = LinearSVC(multi_class= \"ovr\")\n",
    ")\n",
    "classifier_svc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score for LinearSVC Classifer Chain: 0.7907671549730146\n",
      "Validation Score for LinearSVC Classifer Chain: 0.3338473400154202\n",
      "Validation Recall for LinearSVC Classifer Chain: 0.5321232697832332\n",
      "Validation Precision for LinearSVC Classifer Chain: 0.6822367319604888\n"
     ]
    }
   ],
   "source": [
    "#Train score\n",
    "print(\"Training Score for LinearSVC Classifer Chain:\", \n",
    "      classifier_svc.score(X_train, Y_train))\n",
    "print(\"Validation Score for LinearSVC Classifer Chain:\",\n",
    "     classifier_svc.score(X_valid, np.array(y_valid_Q1)))\n",
    "\n",
    "y_pred = classifier_svc.predict(X_valid)\n",
    "print(\"Validation Recall for LinearSVC Classifer Chain:\",\n",
    "      recall_score(np.array(y_valid_Q1), y_pred, average= 'micro'))\n",
    "print(\"Validation Precision for LinearSVC Classifer Chain:\",\n",
    "     precision_score(np.array(y_valid_Q1), y_pred, average= 'micro'))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8729869538341413"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall score for training \n",
    "\n",
    "y_pred = classifier_svc.predict(X_train)\n",
    "recall_score(Y_train, y_pred, average= 'micro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
