{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model for Question 1 (data from 2013, 2018, 2020)\n",
    "### Tfid Vectorizer Representation and Classifier Chains model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This code is from preprocessing to be used before \n",
    "#### running code below to create clean texts for fitting \n",
    "#----------------------------------------------------------------\n",
    "\n",
    "# #Create class object\n",
    "# c_pp = comment_preprocessor()\n",
    "\n",
    "# #clean X training set\n",
    "# clean_doc_train, vocab_train = c_pp.preprocess_text(list(X_train_Q1['Comment']))\n",
    "# #clean X valid\n",
    "# clean_doc_valid, vocab_valid = c_pp.preprocess_text(list(X_valid_Q1['Comment']))\n",
    "\n",
    "# ## For baseline, convert list of lists into list of sentences using the following code\n",
    "\n",
    "# clean_text = []\n",
    "# for docs in clean_doc_train:\n",
    "#     clean_text.append(' '.join(docs)) \n",
    "\n",
    "# #save clean text \n",
    "# X_train_Q1['clean_text'] = clean_text\n",
    "# X_train_Q1.to_csv('data/X_train_Q1_clean.csv', index=False)\n",
    "\n",
    "# #validation set preprocess\n",
    "# clean_text_val = []\n",
    "# for docs in clean_doc_valid:\n",
    "#     clean_text_val.append(' '.join(docs))\n",
    "\n",
    "# #save valid clean text \n",
    "# X_valid_Q1['clean_text'] = clean_text_val\n",
    "# X_valid_Q1.to_csv('data/X_valid_Q1_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in preprocessed train and validation datas\n",
    "#your path here\n",
    "\n",
    "X_train_Q1 = pd.read_csv('data/X_train_Q1_clean.csv')\n",
    "X_valid_Q1 = pd.read_csv('data/X_valid_Q1_clean.csv')\n",
    "\n",
    "y_train_Q1 = pd.read_csv('data/y_train_Q1.csv')\n",
    "y_valid_Q1 = pd.read_csv('data/y_valid_Q1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfid Vectorizer Representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfid Vectorizer Representation\n",
    "\n",
    "def tfid_vectorizer(train, valid):\n",
    "    tfid = TfidfVectorizer() \n",
    "    X = tfid.fit_transform(train)\n",
    "    X_valid = tfid.transform(valid)\n",
    "    return X, X_valid\n",
    "\n",
    "#bow = pd.DataFrame(X_train_tfid, columns=sorted(tfid.vocabulary_), index=final_comments)\n",
    "#X_valid_tfid = tfid.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(X_train_Q1['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize X_train and convert Y_train to an array\n",
    "\n",
    "X_train, X_valid = tfid_vectorizer(X_train_Q1['clean_text'].values.astype('U'), \n",
    "                                    X_valid_Q1['clean_text'].values.astype('U')) #had to convert type \n",
    "Y_train = (np.array(y_train_Q1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier_Chain(base_classifier):\n",
    "    classifier_chain = ClassifierChain(\n",
    "        base_classifier\n",
    ")\n",
    "    classifier_chain.fit(X_train, Y_train)\n",
    "    print(\"Training accuracy:\", classifier_chain.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7072089437162683\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC(multi_class= \"crammer_singer\")\n",
    "#\"crammer_singer\" optimizes a joint objective over all classes.\n",
    "\n",
    "Classifier_Chain(LinearSVC(multi_class= \"crammer_singer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=GaussianNB(priors=None, var_smoothing=1e-09),\n",
       "                order=None, require_dense=[True, True])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GaussianNB inhernetly multiclass, sample labelled only one class\n",
    "\n",
    "classifier_gnb = ClassifierChain(\n",
    "    classifier = GaussianNB()\n",
    ")\n",
    "classifier_gnb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier_gnb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3554356206630686"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_gnb.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> train results too low, will not use during GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     loss='squared_hinge', max_iter=1000,\n",
       "                                     multi_class='ovr', penalty='l2',\n",
       "                                     random_state=None, tol=0.0001, verbose=0),\n",
       "                order=None, require_dense=[True, True])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LinearSVC multi_class= \"ovr\"\n",
    "#Multiclass as One-Vs-The-Rest:\n",
    "\n",
    "classifier_svc = ClassifierChain(\n",
    "    classifier = LinearSVC(multi_class= \"ovr\")\n",
    ")\n",
    "classifier_svc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score for LinearSVC Classifer Chain: 0.7907671549730146\n",
      "Validation Score for LinearSVC Classifer Chain: 0.3338473400154202\n",
      "Validation Recall for LinearSVC Classifer Chain: 0.6822367319604888\n",
      "Validation Precision for LinearSVC Classifer Chain: 0.5321232697832332\n"
     ]
    }
   ],
   "source": [
    "#Train score\n",
    "print(\"Training Score for LinearSVC Classifer Chain:\", \n",
    "      classifier_svc.score(X_train, Y_train))\n",
    "print(\"Validation Score for LinearSVC Classifer Chain:\",\n",
    "     classifier_svc.score(X_valid, np.array(y_valid_Q1)))\n",
    "\n",
    "y_pred = classifier_svc.predict(X_valid)\n",
    "print(\"Validation Recall for LinearSVC Classifer Chain:\",\n",
    "      recall_score(y_pred, np.array(y_valid_Q1), average= 'micro'))\n",
    "print(\"Validation Precision for LinearSVC Classifer Chain:\",\n",
    "     precision_score(y_pred, np.array(y_valid_Q1), average= 'micro'))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8729869538341413"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall score for training \n",
    "\n",
    "y_pred = classifier_svc.predict(X_train)\n",
    "recall_score(Y_train, y_pred, average= 'micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> decent accuracy for train set, low for validation. will tune hyperparameters during gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for LinearSVC(multi_class='ovr')\n",
    "\n",
    "* next steps: find way to Grid search with multi label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-16c972e1de23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifierChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The best parameter combination is {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The accuracy on the valid split is {:.2f}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid_Q1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/skmultilearn/problem_transform/cc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, order)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             self.classifiers_[label] = self.classifier.fit(self._ensure_input_format(\n\u001b[0;32m--> 155\u001b[0;31m                 X_extended), self._ensure_output_format(y_subset))\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mX_extended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_extended\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# ---------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n\u001b[1;32m    231\u001b[0m                              % self.C)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "#hyperparameter search for LinearSVC\n",
    "\n",
    "parameters = [\n",
    "    {'classifier': [LinearSVC()],\n",
    "     'classifier__C': [np.logspace(-3,3,7)]}\n",
    "    # 'classifier__penalty':['l1','l2'],\n",
    "    # 'classifier__loss': ['hinge', 'squared_hinge']}\n",
    "]\n",
    "    \n",
    "clf = GridSearchCV(ClassifierChain(), parameters, scoring= 'accuracy')\n",
    "clf.fit(X_train, Y_train)\n",
    "print('The best parameter combination is {}.'.format(clf.best_params_))\n",
    "print('The accuracy on the valid split is {:.2f}.'.format(clf.score(X_valid, np.array(y_valid_Q1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search using Multinomial Naive Bayes or SVC which supports sparse input\n",
    "parameters = [\n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.7, 1.0],\n",
    "    },\n",
    "    {\n",
    "        'classifier': [LinearSVC(multi_class= \"ovr\")],\n",
    "        'classifier__kernel': ['rbf', 'linear'],\n",
    "    },\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(ClassifierChain(), parameters, scoring='accuracy')\n",
    "clf.fit(X_sample, Y_sample)\n",
    "\n",
    "print (clf.best_params_, clf.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
