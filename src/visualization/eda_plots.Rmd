---
title: "EDA"
output: github_document
author: "by Victor Cuspinera"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

These EDA's plots in R could be used for the R Shinny app, and/or give us ideas for the BC Stats Capstone Project.

## Histograms

```{r dataset question 1, include=FALSE}
train_X_q1_total <- readr::read_csv(file = "../../data/X_train.csv")  # preprocessed train comments
train_X_q1_pp <- readr::read_csv(file = "../../data/X_train_pp.csv")  # preprocessed train comments
train_y_q1 <- readr::read_csv(file = "../../data/y_train.csv")  # themes and subthemes
names <- readr::read_csv(file = "../../data/names_all.csv")  # names of the variables

train_y_q1 <- train_y_q1 %>% rename(
  Career_Personal_Development = CPD,
  Compensation_Benefits = CB,
  Engagement_Workplace_Culture = EWC,
  Executives = Exec,
  Flexible_Work_Environment = FEW,
  Staffing_Practices = SP,
  Recognition_Empowerment = RE,
  Supervisors = Sup,
  Stress_Workload = SW,
  Tools_Equipment_Physical_Environment = TEPE,
  Vision_Mission_Goals = VMG,
  Other  = OTH,
  Unrelated_comments = Unrelated
)
```

### Themes - question 1

13 themes:
  Career_Personal_Development = CPD,
  Compensation_Benefits = CB,
  Engagement_Workplace_Culture = EWC,
  Executives = Exec,
  Flexible_Work_Environment = FEW,
  Staffing_Practices = SP,
  Recognition_Empowerment = RE,
  Supervisors = Sup,
  Stress_Workload = SW,
  Tools_Equipment_Physical_Environment = TEPE,
  Vision_Mission_Goals = VMG,
  Other  = OTH,
  Unrelated_comments = Unrelated

```{r themes, fig.width=8, fig.height=4, echo=FALSE}
themes_q1 <- cbind(train_y_q1[1:12],train_y_q1[length(train_y_q1)])
themes_q1 <- themes_q1 %>% summarise_all(sum) %>% 
  stack() %>% select(ind, values) %>% 
  rename(
    themes = ind,
    count = values
  ) %>% 
  arrange(count) %>% 
  mutate(themes=factor(themes, levels=themes)) 

themes_q1 %>% ggplot(aes(x=themes, y=count)) +
  geom_col(aes(alpha=count), fill="dodgerblue4") +
  geom_text(aes(label=count, y=count+120), color="gray45") +
  labs(title="Number of comments for Themes", 
       subtitle="Question 1 - training dataset") +
  coord_flip() +
  theme_bw() +
  theme(legend.position = "none")
```

### Sub-themes - question 1

63 themes

```{r subthemes, fig.width=9, fig.height=10, echo=FALSE}
subthemes_q1 <- train_y_q1[13:length(train_y_q1)]

subthemes_q1 <- subthemes_q1 %>% summarise_all(sum) %>%
  stack() %>% select(ind, values) %>%
  rename(
    subthemes = ind,
    count = values
  ) %>%
  arrange(count) %>%
  mutate(subthemes=factor(subthemes, levels=subthemes)) 

subthemes_q1 %>% ggplot(aes(x=subthemes, y=count)) +
  geom_col(aes(alpha=count), fill="dodgerblue4") +
  geom_text(aes(label=count, y=count+70), color="gray45") +
  labs(title="Number of comments for Sub-themes", 
       subtitle="Question 1 - training dataset")+
  coord_flip() +
  theme_bw() +
  theme(legend.position = "none")
```

### Sub-themes group by Theme - question 1

```{r subthemes_per_themes, fig.width=10, fig.height=15, echo=FALSE}
all_q1 <- train_y_q1[13:length(train_y_q1)]

all_q1 <- all_q1 %>% summarise_all(sum) %>%
  stack() %>% select(ind, values) %>%
  rename(
    subthemes = ind,
    count = values
  ) %>%
  arrange(count) %>%
  mutate(subthemes=sub("EWC - Other", "EWC_Other", subthemes)) %>% 
  mutate(subthemes=factor(subthemes, levels=subthemes))

library("stringr")

all_q1 %>% ggplot(aes(x=subthemes, y=count)) +
  geom_col(aes(fill=-count)) +
  geom_text(aes(label=count, y=count+70), color="gray45") +
  labs(title="Number of comments for Theme and Sub-themes", 
       subtitle="Question 1 - training dataset") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 30, hjust=1)) +
  theme(legend.position = "none") +
  facet_wrap(vars(str_extract(string = all_q1$subthemes, 
                              pattern = "([A-Z][A-Za-z]+)(?=_)")),
                              scales = "free_x")
```

### Relation between themes - question 1
```{r relation between themes, echo=FALSE}
theme_aux <- cbind(train_y_q1[1:12],train_y_q1[length(train_y_q1)])

for (i in 1:nrow(theme_aux)){
  for (j in 1:ncol(theme_aux)){
    if (theme_aux[i, j]==1){
      theme_aux[i, j] <- colnames(theme_aux)[j]
    } else {
      theme_aux[i, j] = ""
    }
  }
}

relation_themes <- unite(theme_aux, col = "themes", 
                         # here I write the 13 themes:
                         "Career_Personal_Development", 
                         "Compensation_Benefits",
                         "Engagement_Workplace_Culture", 
                         "Executives", 
                         "Flexible_Work_Environment",
                         "Staffing_Practices",
                         "Recognition_Empowerment",
                         "Supervisors", "Stress_Workload",
                         "Tools_Equipment_Physical_Environment",
                         "Vision_Mission_Goals", 
                         "Other", "Unrelated_comments",
                          sep=" ")

# filter(relation_themes, themes == "Executives")
# str_detect(relation_themes[[1]], regex("NA", ignore_case=FALSE))

#fig.width=6, fig.height=6,
library(dplyr)
library(tidytext)
library(igraph)
library(ggraph)

set.seed(42)

# # uncomment and run the next code only once to have the right format:
relation_themes <- tibble::rowid_to_column(relation_themes, "ID")

# making the bigrams
bigrams_themes <- data.frame(relation_themes) %>%
  unnest_tokens(bigram, themes, token ="ngrams", n=2)

bigrams_themes[is.na(bigrams_themes)] <- "unique_theme unique_theme"

# count bigrams
bigram_counts <- bigrams_themes %>%
  count(bigram, sort = TRUE) %>%
  separate(bigram, c("theme1", "theme2"), sep = " ") %>%
  filter(!theme1 %in% stop_words$word) %>%
  filter(!theme2 %in% stop_words$word)

# filter for only relatively common combinations
number_repetitions <- 30
bigram_graph <- bigram_counts %>%
  filter(theme1 != "unique_theme") %>%
  filter(n > number_repetitions) %>%
  graph_from_data_frame()

# plot
arrow_type <- grid::arrow(type = "closed", length = unit(5, "mm"))

bigram_graph %>% ggraph(layout = "linear", circular=TRUE) +
  geom_edge_link(aes(edge_alpha = n, colour=n, label=n), show.legend = FALSE,
                 arrow = arrow_type, end_cap = circle(.07, 'inches')) +
  geom_edge_loop(aes(label=n), colour = "red") +
  geom_node_point(color = "salmon", size = 3) +
  #geom_edge_arc(aes(edge_alpha = n, colour =n, label=n), arrow = arrow_type,) +
  geom_node_text(aes(label = name), vjust = 1, hjust = .5) +
  theme_void() 
```


### Themes - question 2 (supervised dataset: 2018)

```{r dataset question 2, include=FALSE}
train_X_q2_total <- readr::read_csv(file = "../../data/X_train_q2.csv")  # preprocessed train comments
train_X_q2_pp <- readr::read_csv(file = "../../data/X_train_q2_pp.csv")  # preprocessed train comments
train_y_q2 <- readr::read_csv(file = "../../data/y_train_q2.csv")  # themes and subthemes
names <- readr::read_csv(file = "../../data/names_all.csv")  # names of the variables
```

```{r themes Q2, fig.width=8, fig.height=4, echo=FALSE}
themes_q2 <- train_y_q2 %>% summarise_all(sum) %>% 
  stack() %>% select(ind, values) %>% 
  rename(
    themes = ind,
    count = values
  ) %>% 
  arrange(count) %>% 
  mutate(themes=factor(themes, levels=themes)) 

themes_q2 %>% ggplot(aes(x=themes, y=count)) +
  geom_col(aes(alpha=count), fill="dodgerblue4") +
  geom_text(aes(label=count, y=count+30), color="gray45") +
  labs(title="Number of comments for Themes", 
       subtitle="Question 2 (supervised) - training dataset") +
  coord_flip() +
  theme_bw() +
  theme(legend.position = "none")
```

## Analysis by Words

*Note: [__library `tokenizers`__, tokenization package in R](https://cran.r-project.org/web/packages/tokenizers/vignettes/introduction-to-tokenizers.html)*
```{r tokens, echo=FALSE}
library(tokenizers)
tokens_original = tokenize_words(train_X_q1_total$Comment)
tokens_pp = tokenize_words(train_X_q1_pp$Comment)
```

### Number of words - question 1

```{r number words, fig.width=10, fig.height=15, echo=FALSE}
words_per_comment = data.frame(
  row = c(1:length(tokens_original)),
  words_original = count_words(train_X_q1_total$Comment),
  words_pp = count_words(train_X_q1_pp$Comment)
)
```

```{r plot number words, fig.width=6, fig.height=3.5, echo=FALSE}
colors <- c("Original" = "salmon", "Preprocess" = "dodgerblue4")

words_plot <- words_per_comment %>% ggplot() +
  geom_density(aes(words_original, fill="Original"), alpha=0.7) +
  geom_density(aes(words_pp, fill="Preprocess"), alpha=0.5) +
  labs(title="Distribution of words for Original and Preprocess Comments",
     subtitle="Question 1 - training dataset", 
     x="number of words",
     y="density",
     fill = "Dataset") +
  theme_bw() +
  scale_fill_manual(values = colors)

words_plot
```

### Number of words with log scale - question 1

```{r plot number words log-scale, fig.width=6, fig.height=3.5, echo=FALSE}
words_plot + scale_x_log10() +
  labs(title="Distribution of words for Original and Preprocess Comments - log scale",
     x="log(number of words)")
```

### Wordcloud - question 1

```{r wordcloud, echo=FALSE}
library(tm)
library(wordcloud)

docs <- Corpus(VectorSource(train_X_q1_pp$Comment))  # Create a corpus

dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- rowSums(matrix)
df <- data.frame(freq=words)

set.seed(42) # for reproducibility
wordcloud(words = rownames(df), freq = df$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```

### Wordcloud - question 2 (Unsupervised dataset: 2015, 2018, 2020)

```{r wordcloud question 2, echo=FALSE}
# read ata
unsupervised_q2 <- readr::read_csv(file = "../../data/unsuperv_q2_pp.csv")

# wordcloud code
docs_q2 <- Corpus(VectorSource(unsupervised_q2$Comment))  # Create a corpus

dtm_q2 <- TermDocumentMatrix(docs_q2)
matrix_q2 <- as.matrix(dtm_q2)
words_q2 <- rowSums(matrix_q2)
df_q2 <- data.frame(freq=words_q2)

set.seed(42) # for reproducibility
wordcloud(words = rownames(df_q2), freq = df_q2$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```

**Maybe it would be good to see the sentiment analysis of the words for both questions and compare them.**

### Comparing words - question 1 vs. question 2

```{r words q1 vs q2, fig.width=7, fig.height=7, echo=FALSE}
library(tidyr)
library(scales)

# Dataframe of words from both questions
aux_q1 <- tibble(words = names(words), question_1=df$freq)
aux_q2 <- tibble(words = names(words_q2), question_2=df_q2$freq)
both_q <- full_join(aux_q1, aux_q2, by="words")
both_q[is.na(both_q)] <- 0

# frequency
frequency <- both_q %>%
  mutate(question_1 = question_1 / sum(both_q$question_1),
         question_2 = question_2 / sum(both_q$question_2))

# expect a warning about rows with missing values being removed
ggplot(frequency, aes(x = question_1, y = question_2, color = abs(question_1 + question_2))) +
  geom_abline(color = "salmon", lty = 2, size =1) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = words), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(trans = "log", low = "dodgerblue2", high = "gray20") +
  labs(title="Frequency of words", subtitle = "Question 1 vs. question 2 (unsupervised)",
       x = "Question 1", y = "Question 2") +
  theme_bw() +
  theme(legend.position="none")
```

It looks like both questions have words with close frequencies of repetitions.

## Sentiment Analysis

### Top positive and negative words - question 1 and question 2

```{r sentiment 1, fig.width=8, fig.height=8, echo=FALSE}
library(tidytext)
library(magrittr)
library(multipanelfigure)
require(gridExtra)

colors2 <- c("Question 1"="darkgreen", "Question 2"="orange")

# sentiment dataframe
sentiments <- merge(frequency, get_sentiments("bing"),
                    by.x="words", by.y="word")
sentiments <- sentiments %>% arrange(question_1, question_2) %>% 
  mutate(words=factor(words, levels=words))

# positive plot
positive_plot <- sentiments %>% filter(sentiment == "positive") %>%
  tail(60) %>%
  ggplot(aes(x=words)) +
  geom_col(aes(y=question_1, fill="Question 1"), alpha=0.7) +
  geom_col(aes(y=question_2, fill="Question 2"), alpha=0.6) +
  facet_wrap(~sentiment, scales = "free_y") +
  coord_flip() +
  labs(title="Sentiment Analysis",
     y="Density",
     fill = "Dataset") +
  theme_bw() +
  scale_fill_manual(values = colors2) +
  scale_y_continuous(labels = percent_format()) +
  theme(legend.position = "none") 

# negative plot
negative_plot <- sentiments %>% filter(sentiment == "negative") %>%
  tail(60) %>%
  ggplot(aes(x=words)) +
  geom_col(aes(y=question_1, fill="Question 1"), alpha=0.7) +
  geom_col(aes(y=question_2, fill="Question 2"), alpha=0.5) +
  facet_wrap(~sentiment, scales = "free_y") +
  coord_flip() +
  labs(title=" ",
       y="Density",
       x="",
     fill = "Dataset") +
  theme_bw() +
  scale_fill_manual(values = colors2) +
  scale_y_continuous(labels = percent_format())

# put together both plots
both_plots <- multi_panel_figure(columns = 7, rows = 1, 
                                 panel_label_type = "none")
both_plots %<>%
  fill_panel(positive_plot, column = 1:3, row = 1) %<>%
  fill_panel(negative_plot, column = 4:7, row = 1)
both_plots
```

### Wordcloud sentiment - question 1

```{r sentiment q1, fig.width=8, fig.height=4, echo=FALSE}
library(reshape2)

sentiments %>% 
  acast(words ~ sentiment, value.var = "question_1", fill = 0) %>%
  comparison.cloud(colors = c("salmon", "dodgerblue4"),
                   max.words = 90)
```

### Wordcloud sentiment - question 2

```{r sentiment q2, fig.width=8, fig.height=4, echo=FALSE}
library(reshape2)

sentiments %>% 
  acast(words ~ sentiment, value.var = "question_2", fill = 0) %>%
  comparison.cloud(colors = c("salmon", "dodgerblue4"),
                   max.words = 90)
```

## n-grams

### Cloud of biagrams - question 1

```{r bigrams quesrtion 1,  echo=FALSE}
#fig.width=6, fig.height=6,
library(dplyr)
library(tidytext)
library(igraph)
library(ggraph)

set.seed(42)

# # uncomment and run the next code only once to have the right format:
train_X_q1_pp <- tibble::rowid_to_column(train_X_q1_pp, "ID")

# making the bigrams
bigrams_q1 <- data.frame(train_X_q1_pp) %>%
  unnest_tokens(bigram, Comment, token ="ngrams", n=2)

# count bigrams
bigram_counts <- bigrams_q1 %>% 
  count(bigram, sort = TRUE) %>% 
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# filter for only relatively common combinations
number_repetitions <- 40
bigram_graph <- bigram_counts %>%
  filter(n > number_repetitions) %>%
  graph_from_data_frame()

# plot
arrow_type <- grid::arrow(type = "closed", length = unit(2, "mm"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = arrow_type, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "salmon", size = 3) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()

# ggraph(bigram_graph, layout = "graphopt") +
#   geom_edge_link(aes(edge_alpha = n, star_cap = label_rect(node1.name),
#                      end_cap = label_rect(node2.name)),
#                  arrow = arrow_type) +
#   geom_node_point(color = "salmon", size = 3) +
#   geom_node_text(aes(label = name)) +
#   theme_void()
```


## References
- [Bryan J. (2019). **STAT 545, Data wrangling, exploration, and analysis with R.** Chapter 15 Join two tables](https://stat545.com/join-cheatsheet.html)
- [Data Imaginist. (2020). **Introduction to ggraph: Edges**. Retrieved 2020-05-17](https://www.data-imaginist.com/2017/ggraph-introduction-edges/)
- [Mullen L. (2018). **Introduction to the tokenizers Package.** CRAN R-project.](https://cran.r-project.org/web/packages/tokenizers/vignettes/introduction-to-tokenizers.html)
- [Silge J., Robinson D. (2020-03-07). **Text Mining with R.** Retrieved: 2020-05-16](https://www.tidytextmining.com)
